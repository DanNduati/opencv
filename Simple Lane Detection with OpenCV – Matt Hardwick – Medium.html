<!DOCTYPE html>
<html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>Simple Lane Detection with OpenCV – Matt Hardwick – Medium</title><link rel="canonical" href="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0"><meta name="title" content="Simple Lane Detection with OpenCV – Matt Hardwick – Medium"><meta name="referrer" content="always"><meta name="description" content="This post is the second in my series about the projects and challenges of Udacity’s nano-degree on self-driving vehicle engineering. In this post, we’ll be doing a deep dive on the techniques that…"><meta name="theme-color" content="#000000"><meta property="og:title" content="Simple Lane Detection with OpenCV – Matt Hardwick – Medium"><meta property="og:url" content="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/1*a2owzhUlg_3telqyYz7avA.png"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="Using OpenCV and Python to Detect Road Lanes"><meta name="twitter:description" content="Using OpenCV and Python to Detect Road Lanes"><meta name="twitter:image:src" content="https://cdn-images-1.medium.com/max/1200/1*a2owzhUlg_3telqyYz7avA.png"><link rel="publisher" href="https://plus.google.com/103654360130207659246"><link rel="author" href="https://medium.com/@mrhwick"><meta property="author" content="Matt Hardwick"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta property="article:publisher" content="https://www.facebook.com/medium"><meta property="article:author" content="Matt Hardwick"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2017-03-20T18:21:42.388Z"><meta name="twitter:creator" content="@MRHwick"><meta name="twitter:site" content="@Medium"><meta property="og:site_name" content="Medium"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="18 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/bfeb6ae54ec0"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/bfeb6ae54ec0"><meta property="al:android:url" content="medium://p/bfeb6ae54ec0"><meta property="al:web:url" content="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/bfeb6ae54ec0"><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":1920,"height":548,"url":"https://cdn-images-1.medium.com/max/1920/1*a2owzhUlg_3telqyYz7avA.png"},"datePublished":"2017-03-20T18:21:42.388Z","dateModified":"2018-05-06T04:20:51.896Z","headline":"Simple Lane Detection with OpenCV","name":"Simple Lane Detection with OpenCV","keywords":["Machine Learning","Udacity","Self Driving Cars","Autonomous Cars","Opencv"],"author":{"@type":"Person","name":"Matt Hardwick","url":"https://medium.com/@mrhwick"},"creator":["Matt Hardwick"],"publisher":{"@type":"Organization","name":"Medium","url":"https://medium.com/","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https://cdn-images-1.medium.com/max/308/1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0"}</script><link rel="stylesheet" type="text/css" class="js-glyph-" id="glyph-12" href="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/m2.css"><link rel="stylesheet" href="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/main-branding-base.css"><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");</script><script async="" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/analytics.js"></script><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"></head><body itemscope="" class=" postShowScreen browser-firefox is-withMagicUnderlinesv-glyph v-glyph--m2 is-js is-withMagicUnderlines" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--error" data-action-scope="_actionscope_1"></div><div class="surface" id="_obv.shell._surface_1526497277835" style="display: block; visibility: visible;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-used="true" data-action-scope="_actionscope_2"><canvas class="canvas-renderer" width="1352" height="645"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_4"></div></div><div class="metabar u-clearfix js-metabar u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth"><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1000 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingLeft20 u-paddingRight20"><div class="metabar-block u-flex1 u-flexCenter"><div class="js-metabarLogoLeft u-xs-show"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo"><span class="svgIcon svgIcon--logoWordmark svgIcon--138x27px is-flushLeft u-xs-hide u-textColorDarker"><svg class="svgIcon-use" width="138" height="27" viewBox="0 0 138 27"><path d="M130 27V16.96c0-3.26-.154-5.472-2.437-5.472-1.16 0-2.138.57-2.863 1.512.217.906.3 1.968.3 3.127 0 2.247.036 5.11 0 7.973 0 .472-.046.58.244.87L127 27h-8V16.96c0-3.297-.461-5.472-2.708-5.472-1.16 0-1.64.653-2.292 1.595V24.1c0 .472-.026.58.3.87L116 27h-8V11.56c0-.47-.07-.579-.36-.905L106 9h8v3.612c.906-2.537 2.437-4.112 5.372-4.112 2.682 0 4.494 1.466 5.255 4.257.834-2.392 3.008-4.257 6.053-4.257 3.588 0 5.32 2.626 5.32 7.627 0 2.392.036 5.11 0 7.973 0 .472.004.652.25.87L138 27h-8zm-27-3.045c0 .472-.149.617.178.906L105 27h-8v-4c-.906 2.465-2.956 4-5.637 4C87.775 27 86 24.39 86 19.461c0-2.391-.036-5 0-7.936 0-.471-.11-.58-.4-.87L84 9h8v9.628c0 3.225.269 5.4 2.298 5.4 1.16 0 2.086-.725 2.702-1.63V11.56c0-.471-.129-.58-.419-.906L95 9h8v14.955zM78.002.25A3.248 3.248 0 0 1 81.25 3.5 3.25 3.25 0 1 1 78.002.25zM75 27V11.56c0-.47.168-.579-.122-.905L73 9h8v15.1c0 .472-.01.678.24.9L83 27h-8zM64 11.706c-.507-.652-1.418-1.123-2.396-1.123-1.957 0-3.842 1.775-3.842 7.03 0 4.93 1.631 6.669 3.66 6.669.907 0 1.853-.436 2.578-1.378V11.706zm6 12.286c0 .47-.026.58.3.87L72 27h-8v-3.697C62.913 25.804 60.951 27 58.632 27 54.5 27 51.5 23.738 51.5 17.795c0-5.582 3.254-9.314 7.784-9.314 2.356 0 3.919 1.123 4.716 2.899V3.878c0-.471-.077-.617-.403-.906L62 1.305 70 .29v23.702zM43.9 16c.037-.471.037-.67.037-.815 0-4.747-.937-5.435-2.437-5.435-1.5 0-2.854.995-2.927 6.25h5.328zm-5.327 1c0 4.711 2.392 6.63 5.183 6.63 2.174 0 4.313-.943 5.509-3.335h.072c-.942 4.566-3.77 6.705-8.01 6.705-4.566 0-8.879-2.755-8.879-9.133 0-6.705 4.277-9.386 9.097-9.386 3.842 0 7.937 1.811 7.937 7.646 0 .109 0 .438-.036.873H38.573zM31.5 27h-12l2.39-2.646c.084-.084.11-.399.11-.87V7l-7.866 20L5.581 8.372C5.364 7.9 5.181 7.285 5 6.777V20.62c0 .58-.035.653.364 1.196L9 27H0l3.64-5.183c.399-.543.36-.616.36-1.196V6.27c0-.617.095-.69-.195-1.051L1 1h8.495l7.355 16.3L23.24 1h8.26l-2.2 2.75c-.326.326-.3.599-.3 1.106v18.629c0 .47.005.75.138.87L31.5 27z"></path></svg></span><span class="svgIcon svgIcon--logoWordmark svgIcon--122x45px is-flushLeft u-xs-show u-textColorDarker"><svg class="svgIcon-use" width="122" height="45" viewBox="0 0 122 45"><path d="M61.6 31.806c0 .412 0 .505.28.758l1.574 1.537v.065h-6.979v-2.95a4.852 4.852 0 0 1-4.627 3.203c-3.588 0-6.192-2.81-6.192-7.981 0-4.843 2.81-8.075 6.754-8.075a4.122 4.122 0 0 1 4.056 2.51v-6.51a.806.806 0 0 0-.319-.787l-1.499-1.443v-.065l6.951-.815v20.553zm-5.125-.937v-9.714a2.614 2.614 0 0 0-2.08-.975c-1.695 0-3.334 1.537-3.334 6.099 0 4.271 1.414 5.78 3.175 5.78a2.81 2.81 0 0 0 2.24-1.19zm9.752 3.297V21.051a.88.88 0 0 0-.281-.786L64.4 18.672v-.065h6.98v13.302c0 .412 0 .505.28.758l1.536 1.443v.066l-6.97-.01zm-.253-20.356a2.81 2.81 0 1 1 5.62 0 2.81 2.81 0 0 1-5.62 0zm24.234 17.967c0 .413 0 .534.281.787l1.574 1.537v.065h-7.017v-3.363a5.077 5.077 0 0 1-4.805 3.616c-3.11 0-4.778-2.267-4.778-6.557 0-2.07 0-4.337.066-6.885a.796.796 0 0 0-.281-.76l-1.546-1.545v-.065h6.923v8.552c0 2.81.412 4.684 2.173 4.684a2.81 2.81 0 0 0 2.267-1.415v-9.367a.88.88 0 0 0-.28-.787l-1.556-1.602v-.065h6.979v13.17zm23.756 2.39c0-.507.094-6.952.094-8.432 0-2.81-.44-4.75-2.417-4.75a3.138 3.138 0 0 0-2.482 1.35c.198.876.292 1.772.28 2.67 0 1.948-.065 4.43-.093 6.913a.796.796 0 0 0 .281.759l1.574 1.442v.066h-7.045c0-.468.094-6.95.094-8.431 0-2.857-.44-4.75-2.389-4.75a2.81 2.81 0 0 0-2.323 1.387v9.555c0 .412 0 .506.281.759l1.537 1.442v.066h-6.97V21.098a.88.88 0 0 0-.281-.787l-1.546-1.639v-.065h6.98v3.334a5.002 5.002 0 0 1 5.002-3.587c2.323 0 3.896 1.292 4.562 3.747a5.433 5.433 0 0 1 5.245-3.747c3.11 0 4.872 2.295 4.872 6.632 0 2.07-.066 4.43-.094 6.913a.75.75 0 0 0 .318.759l1.537 1.443v.065h-7.017zm-87.671-2.043l2.07 1.977v.065H17.862v-.065l2.107-1.977a.796.796 0 0 0 .281-.759V18.728c0-.534 0-1.255.094-1.873l-7.082 17.564h-.084L5.843 18.26c-.16-.402-.206-.43-.31-.702v10.595c-.087.71.034 1.429.348 2.07l2.95 3.879v.065H1v-.065l2.95-3.888a3.69 3.69 0 0 0 .347-2.06v-11.71a2.267 2.267 0 0 0-.487-1.602l-2.089-2.708v-.065h7.494l6.277 13.686 5.527-13.686h7.335v.065l-2.061 2.296a.806.806 0 0 0-.319.786v16.15a.75.75 0 0 0 .319.759zm8.215-6.332v.065c0 4.01 2.07 5.62 4.497 5.62a5.105 5.105 0 0 0 4.777-2.894h.066c-.844 3.963-3.298 5.836-6.97 5.836-3.962 0-7.7-2.389-7.7-7.925 0-5.817 3.747-8.14 7.887-8.14 3.335 0 6.886 1.573 6.886 6.632v.806h-9.443zm0-.806h4.618v-.815c0-4.122-.852-5.218-2.136-5.218-1.555 0-2.5 1.64-2.5 6.033h.018z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><a class="link link--darken u-accentColor--textDarken u-baseColor--link u-xs-hide js-upgradeMembershipAction" href="https://medium.com/membership?source=upgrade_membership---nav_full" data-scroll="native">About membership</a></div><div class="metabar-block u-flex0"><div class="buttonSet buttonSet--wide"><a class="button button--primary button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fmedium.com%2F%40mrhwick%2Fsimple-lane-detection-with-opencv-bfeb6ae54ec0&amp;source=--------------------------nav_reg&amp;operation=login" data-action="sign-in-prompt" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-action-source="--------------------------nav_reg">Sign in</a><a class="button button--primary button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fmedium.com%2F%40mrhwick%2Fsimple-lane-detection-with-opencv-bfeb6ae54ec0&amp;source=--------------------------nav_reg&amp;operation=register" data-action="sign-up-prompt" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-action-source="--------------------------nav_reg">Get started</a></div></div><div class="u-absolute u-sizeFullWidth u-top0 u-right0 u-bottom0 u-flexCenter u-justifyContentCenter u-textAlignCenter u-xs-hide js-metabarLogoCentered"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo"><span class="svgIcon svgIcon--logoWordmark svgIcon--138x27px is-flushLeft u-xs-hide u-textColorDarker"><svg class="svgIcon-use" width="138" height="27" viewBox="0 0 138 27"><path d="M130 27V16.96c0-3.26-.154-5.472-2.437-5.472-1.16 0-2.138.57-2.863 1.512.217.906.3 1.968.3 3.127 0 2.247.036 5.11 0 7.973 0 .472-.046.58.244.87L127 27h-8V16.96c0-3.297-.461-5.472-2.708-5.472-1.16 0-1.64.653-2.292 1.595V24.1c0 .472-.026.58.3.87L116 27h-8V11.56c0-.47-.07-.579-.36-.905L106 9h8v3.612c.906-2.537 2.437-4.112 5.372-4.112 2.682 0 4.494 1.466 5.255 4.257.834-2.392 3.008-4.257 6.053-4.257 3.588 0 5.32 2.626 5.32 7.627 0 2.392.036 5.11 0 7.973 0 .472.004.652.25.87L138 27h-8zm-27-3.045c0 .472-.149.617.178.906L105 27h-8v-4c-.906 2.465-2.956 4-5.637 4C87.775 27 86 24.39 86 19.461c0-2.391-.036-5 0-7.936 0-.471-.11-.58-.4-.87L84 9h8v9.628c0 3.225.269 5.4 2.298 5.4 1.16 0 2.086-.725 2.702-1.63V11.56c0-.471-.129-.58-.419-.906L95 9h8v14.955zM78.002.25A3.248 3.248 0 0 1 81.25 3.5 3.25 3.25 0 1 1 78.002.25zM75 27V11.56c0-.47.168-.579-.122-.905L73 9h8v15.1c0 .472-.01.678.24.9L83 27h-8zM64 11.706c-.507-.652-1.418-1.123-2.396-1.123-1.957 0-3.842 1.775-3.842 7.03 0 4.93 1.631 6.669 3.66 6.669.907 0 1.853-.436 2.578-1.378V11.706zm6 12.286c0 .47-.026.58.3.87L72 27h-8v-3.697C62.913 25.804 60.951 27 58.632 27 54.5 27 51.5 23.738 51.5 17.795c0-5.582 3.254-9.314 7.784-9.314 2.356 0 3.919 1.123 4.716 2.899V3.878c0-.471-.077-.617-.403-.906L62 1.305 70 .29v23.702zM43.9 16c.037-.471.037-.67.037-.815 0-4.747-.937-5.435-2.437-5.435-1.5 0-2.854.995-2.927 6.25h5.328zm-5.327 1c0 4.711 2.392 6.63 5.183 6.63 2.174 0 4.313-.943 5.509-3.335h.072c-.942 4.566-3.77 6.705-8.01 6.705-4.566 0-8.879-2.755-8.879-9.133 0-6.705 4.277-9.386 9.097-9.386 3.842 0 7.937 1.811 7.937 7.646 0 .109 0 .438-.036.873H38.573zM31.5 27h-12l2.39-2.646c.084-.084.11-.399.11-.87V7l-7.866 20L5.581 8.372C5.364 7.9 5.181 7.285 5 6.777V20.62c0 .58-.035.653.364 1.196L9 27H0l3.64-5.183c.399-.543.36-.616.36-1.196V6.27c0-.617.095-.69-.195-1.051L1 1h8.495l7.355 16.3L23.24 1h8.26l-2.2 2.75c-.326.326-.3.599-.3 1.106v18.629c0 .47.005.75.138.87L31.5 27z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div></div></div><div class="metabar metabar--spacer js-metabarSpacer u-height65 u-xs-height56"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full u-marginBottom40" lang="en"><header class="container u-maxWidth740"><div class="uiScale uiScale-ui--regular uiScale-caption--regular postMetaHeader u-paddingBottom10 row"><div class="col u-size12of12 js-postMetaLockup"><div class="uiScale uiScale-ui--regular uiScale-caption--regular postMetaLockup postMetaLockup--authorWithBio u-flexCenter js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@mrhwick?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="5736bd18104c" data-action-type="hover" data-user-id="5736bd18104c" dir="auto"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/0w9URdmuBdJxuElHz_003.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Matt Hardwick"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-lineHeightTightest"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://medium.com/@mrhwick?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="5736bd18104c" data-action-type="hover" data-user-id="5736bd18104c" dir="auto">Matt Hardwick</a><span class="followState js-followState" data-user-id="5736bd18104c"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/5736bd18104c" data-action-source="post_header_lockup-5736bd18104c-------------------------follow_byline"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption ui-xs-clamp2 postMetaInline">Software Engineer. Computer Scientist. Fascinated with the world at large and my place in it.</div><div class="ui-caption postMetaInline js-testPostMetaInlineSupplemental"><time datetime="2017-03-20T18:21:42.388Z">Mar 20, 2017</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="18 min read"></span></div></div></div></div></div></header><div class="postArticle-content js-postField js-notesSource js-trackedPost" data-post-id="bfeb6ae54ec0" data-source="post_page" data-tracking-context="postPage" data-scroll="native"><section name="df16" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="e478" id="e478" class="graf graf--h3 graf--leading graf--title">Simple Lane Detection with&nbsp;OpenCV</h1></div><div class="section-inner sectionLayout--outsetColumn"><figure name="5196" id="5196" class="graf graf--figure graf--iframe graf--layoutOutsetCenter graf-after--h3" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia is-canvasLoaded is-imageLoaded" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/resize_003.jpeg" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="56"></canvas><div class="iframeContainer"><iframe data-width="854" data-height="480" data-src="/media/1261e5fbaff3798b46e4cf21ee5a8f53?postId=bfeb6ae54ec0" data-media-id="1261e5fbaff3798b46e4cf21ee5a8f53" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMR5W03V-ldY%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1261e5fbaff3798b46e4cf21ee5a8f53.html" width="980" height="551" frameborder="0"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME data-width="854" data-height="480" width="980" height="551" src="/media/1261e5fbaff3798b46e4cf21ee5a8f53?postId=bfeb6ae54ec0" data-media-id="1261e5fbaff3798b46e4cf21ee5a8f53" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMR5W03V-ldY%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">The
 final product of my own pipeline for lane line detection and rendering 
on a video. We’ll be rebuilding a simpler version of this pipeline in 
this post.</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="8ab1" id="8ab1" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--figure"><span class="graf-dropCap">T</span>his post is the second in <a href="https://medium.com/@mrhwick/embarking-on-a-self-driving-journey-fe368795fe34#.7bnvcuv3v" data-href="https://medium.com/@mrhwick/embarking-on-a-self-driving-journey-fe368795fe34#.7bnvcuv3v" class="markup--anchor markup--p-anchor" target="_blank">my series about the projects and challenges of Udacity’s nano-degree on self-driving vehicle engineering</a>.</p><h3 name="62af" id="62af" class="graf graf--h3 graf-after--p">Introduction</h3><p name="ef46" id="ef46" class="graf graf--p graf-after--h3">In
 this post, we’ll be doing a deep dive on the techniques that I’ve 
learned for a very simple lane detection algorithm. The problem we solve
 in this post is to take a simple video as input data and process it to 
detect the lane within which the vehicle is moving. Then we will find a 
representative line for both the left and right lane lines and render 
those representations back out to the video as a red overlay. This post 
will be heavy on technical details about how to use the libraries 
available in the Python computer vision ecosystem to solve this problem.</p><p name="8311" id="8311" class="graf graf--p graf-after--p">Computer
 vision is an area of computer science devoted to the extraction and 
processing of structured information from mostly-unstructured image 
data. We are going to use <a href="http://opencv.org/" data-href="http://opencv.org/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">OpenCV</a>
 to process the input images to discover any lane lines held within and 
also for rendering out a representation of the lane. Additionally, 
images are really just dense matrix data, so we will use <a href="http://www.numpy.org/" data-href="http://www.numpy.org/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">numpy</a> and <a href="http://matplotlib.org/" data-href="http://matplotlib.org/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">matplotlib</a> to do transformations and rendering of image data. I’ve run all of this code within a <a href="http://jupyter.org/" data-href="http://jupyter.org/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">Jupyter</a> notebook, but you can run it in any environment that allows you to install the dependencies and execute python scripts.</p><p name="0651" id="0651" class="graf graf--p graf-after--p">By the end of this post, you will have learned how to write a program that can do the conversion below.</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="134f" id="134f" class="graf graf--figure graf--layoutOutsetCenter graf-after--p graf--trailing" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 286px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 28.599999999999998%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*a2owzhUlg_3telqyYz7avA.png" data-width="2318" data-height="662" data-action="zoom" data-action-value="1*a2owzhUlg_3telqyYz7avA.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1a2owzhUlg_3telqyYz7avA_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="20"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*a2owzhUlg_3telqyYz7avA.png" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1a2owzhUlg_3telqyYz7avA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*a2owzhUlg_3telqyYz7avA.png"></noscript></div></div><figcaption class="imageCaption">From raw image to rendered lane&nbsp;lines</figcaption></figure></div></div></section><section name="6dd0" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="e94f" id="e94f" class="graf graf--h3 graf--leading">Solving an Easier&nbsp;Problem</h3><p name="e3f0" id="e3f0" class="graf graf--p graf-after--h3">First
 of all, one obvious way to make the problem easier is to work out our 
solution for a single image. A video is, after all, just a series of 
images. We can then move on to running our pipeline on an input video 
frame-by-frame as a final solution to the original problem of processing
 an entire video for lane detection.</p><p name="b801" id="b801" class="graf graf--p graf-after--p">For example, let’s take the single image frame below.</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="5cfd" id="5cfd" class="graf graf--figure graf--layoutOutsetCenter graf-after--p" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 571px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 57.099999999999994%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*BdZPGulJercHGEY6IREMVA.png" data-width="1159" data-height="662" data-action="zoom" data-action-value="1*BdZPGulJercHGEY6IREMVA.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1BdZPGulJercHGEY6IREMVA_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="42"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*BdZPGulJercHGEY6IREMVA.png" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1BdZPGulJercHGEY6IREMVA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*BdZPGulJercHGEY6IREMVA.png"></noscript></div></div><figcaption class="imageCaption">A sample input image&nbsp;frame.</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="c5d0" id="c5d0" class="graf graf--p graf-after--figure">In
 the above image, the lane markers are obvious to any human observer. We
 perform processing of this image intuitively, and after being trained 
to drive a human can detect the lane in which the vehicle appears to be 
moving. Humans also effortlessly identify many other objects in the 
scene, such as the other vehicles, the embankment near the right 
shoulder, some road signs alongside the road, and even the mountains 
visible on the horizon. While many of these objects are complex in 
visual structure, it could be said that the lane markers are actually 
some of the simplest structures in the image!</p><p name="b510" id="b510" class="graf graf--p graf-after--p">Pre-existing
 knowledge of driving gives us certain assumptions about the properties 
and structure of a lane, further simplifying the problem. One obvious 
assumption is that the lane is oriented to be parallel with the 
direction of movement. This being the case, the lines denoting the lane 
will tend to extend from the foreground of an image into the background 
along paths that are angled slightly inwards. We can also assume that 
the lines will never quite reach the horizon, either disappearing with 
distance or being obscured by some other image feature along the way.</p><p name="ea58" id="ea58" class="graf graf--p graf-after--p">One
 very simple filter on the image could be to crop out all of the areas 
which we believe will never contain information about the lane markers. 
We’ll kick off our project by writing the code necessary to do a simple 
crop of the region of interest.</p><h3 name="effe" id="effe" class="graf graf--h3 graf-after--p">Cropping to a Region of&nbsp;Interest</h3><h4 name="309a" id="309a" class="graf graf--h4 graf-after--h3">Loading an Image into&nbsp;Memory</h4><p name="4c5e" id="4c5e" class="graf graf--p graf-after--h4">The
 very first thing we must do before we can process an image is… read an 
image! The following snippet can be used to load an image from a file 
into an array of image data which can be manipulated in python:</p><pre name="241e" id="241e" class="graf graf--pre graf-after--p">import matplotlib.pyplot as plt<br>import matplotlib.image as mpimg</pre><pre name="8b35" id="8b35" class="graf graf--pre graf-after--pre"># reading in an image</pre><pre name="805b" id="805b" class="graf graf--pre graf-after--pre">image = mpimg.imread('solidWhiteCurve.jpg')</pre><pre name="09b8" id="09b8" class="graf graf--pre graf-after--pre"># printing out some stats and plotting the image</pre><pre name="6321" id="6321" class="graf graf--pre graf-after--pre">print('This image is:', type(image), 'with dimensions:', image.shape)<br>plt.imshow(image)<br>plt.show()</pre><p name="ed95" id="ed95" class="graf graf--p graf-after--pre">In this code, we import the necessary library modules, load an image into memory, print some stats about the image, and display it in a plot, as below:</p><pre name="1103" id="1103" class="graf graf--pre graf-after--p">$ python load_image.py<br>This image is: &lt;class 'numpy.ndarray'&gt; with dimensions: (540, 960, 3)</pre></div><div class="section-inner sectionLayout--outsetColumn"><figure name="89e2" id="89e2" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 589px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 58.9%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*sg5ZL439z6b9KtYSOQXCYA.png" data-width="1178" data-height="694" data-action="zoom" data-action-value="1*sg5ZL439z6b9KtYSOQXCYA.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1sg5ZL439z6b9KtYSOQXCYA_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="42"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*sg5ZL439z6b9KtYSOQXCYA.png" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1sg5ZL439z6b9KtYSOQXCYA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*sg5ZL439z6b9KtYSOQXCYA.png"></noscript></div></div><figcaption class="imageCaption">A simple test image which we can use for analysis.</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="6167" id="6167" class="graf graf--p graf-after--figure">Great! Now we have an image in memory which we can now manipulate however we like in our python script. The image has dimensions (540, 960, 3), representing the height, width, and three color channels of the image, respectively. This image will be the example we use for testing our algorithm throughout this post.</p><h4 name="4640" id="4640" class="graf graf--h4 graf-after--p">Defining the Region of&nbsp;Interest</h4><p name="25c0" id="25c0" class="graf graf--p graf-after--h4">Next, we’ll define a set of points which describe the region of interest we want to crop out of the original.</p><p name="05e1" id="05e1" class="graf graf--p graf-after--p">If you have worked with computer graphics before (or even if you paid close attention to the plotted image above!), you realize that the point <code class="markup--code markup--p-code">(0, 0)</code> (the origin) is actually in the upper left corner of the image. This is not exactly intuitive for most people, because general mathematics education tends to only show coordinate systems starting with the origin in the bottom left corner. That being said, this will not cause a lot of complications at this stage aside from the fact that the <code class="markup--code markup--p-code">y</code> coordinates of our region of interest will be specified by their distance from the top of the image rather than from the bottom.</p><p name="e699" id="e699" class="graf graf--p graf-after--p">We want a region of interest that fully contains the lane lines. One simple shape that will achieve this goal is a triangle that begins at the bottom left corner of the image, proceeds to the center of the image at the horizon, and then follows another edge to the bottom right corner of the image. Those vertices are defined as follows:</p><pre name="db78" id="db78" class="graf graf--pre graf-after--p">region_of_interest_vertices = [<br>    (0, height),<br>    (width / 2, height / 2),<br>    (width, height),<br>]</pre><h4 name="6634" id="6634" class="graf graf--h4 graf-after--pre">Cropping the Region of&nbsp;Interest</h4><p name="de43" id="de43" class="graf graf--p graf-after--h4">To actually do the cropping of the image, we’ll define a utility function <code class="markup--code markup--p-code">region_of_interest()</code>:</p><pre name="2a38" id="2a38" class="graf graf--pre graf-after--p">import numpy as np<br>import cv2</pre><pre name="d8cc" id="d8cc" class="graf graf--pre graf-after--pre">def region_of_interest(img, vertices):<br>    # Define a blank matrix that matches the image height/width.<br>    mask = np.zeros_like(img)</pre><pre name="0216" id="0216" class="graf graf--pre graf-after--pre">    # Retrieve the number of color channels of the image.<br>    channel_count = img.shape[2]</pre><pre name="beec" id="beec" class="graf graf--pre graf-after--pre">    # Create a match color with the same color channel counts.<br>    match_mask_color = (255,) * channel_count<br>      <br>    # Fill inside the polygon<br>    cv2.fillPoly(mask, vertices, match_mask_color)<br>    <br>    # Returning the image only where mask pixels match<br>    masked_image = cv2.bitwise_and(img, mask)<br>    return masked_image</pre><p name="e60b" id="e60b" class="graf graf--p graf-after--pre">And then we’ll run the cropping function on our image before showing it again (output below):</p><pre name="6376" id="6376" class="graf graf--pre graf-after--p">import matplotlib.pyplot as plt<br>import matplotlib.image as mpimg</pre><pre name="378b" id="378b" class="graf graf--pre graf-after--pre">region_of_interest_vertices = [<br>    (0, height),<br>    (width / 2, height / 2),<br>    (width, height),<br>]</pre><pre name="dcfe" id="dcfe" class="graf graf--pre graf-after--pre">image = mpimg.imread('solidWhiteCurve.jpg')</pre><pre name="cb9e" id="cb9e" class="graf graf--pre graf-after--pre">cropped_image = region_of_interest(<br>    image,<br>    np.array([region_of_interest_vertices], np.int32),<br>)</pre><pre name="96f8" id="96f8" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(cropped_image)</pre><pre name="473a" id="473a" class="graf graf--pre graf-after--pre">plt.show()</pre></div><div class="section-inner sectionLayout--outsetColumn"><figure name="9ad7" id="9ad7" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 424px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 42.4%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*1OmU-0kFcKljoYdiZk1lGQ.png" data-width="2578" data-height="1092" data-action="zoom" data-action-value="1*1OmU-0kFcKljoYdiZk1lGQ.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/11OmU-0kFcKljoYdiZk1lGQ_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="30"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*1OmU-0kFcKljoYdiZk1lGQ.png" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/11OmU-0kFcKljoYdiZk1lGQ.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*1OmU-0kFcKljoYdiZk1lGQ.png"></noscript></div></div><figcaption class="imageCaption">Cropped image with most of the peripheral objects&nbsp;removed!</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><h3 name="db5b" id="db5b" class="graf graf--h3 graf-after--figure">Detecting Edges in the Cropped&nbsp;Image</h3><p name="79e5" id="79e5" class="graf graf--p graf-after--h3">Now we have a cropped image to work with, in less than 2o lines of code! Even better, we have used a fairly simple shape and yet still managed to remove almost all of the objects from the image that are unrelated to the lane or lane markings.</p><p name="6c64" id="6c64" class="graf graf--p graf-after--p">The next part of our pipeline will be detecting shape edges in the remaining (cropped) image data. We need a bit of mathematical theory to get an intuition about what is happening in this part, but I’m not going to get too technical on the concepts. Interested readers can follow the links provided to learn more.</p><h4 name="8e21" id="8e21" class="graf graf--h4 graf-after--p">Mathematics of Edge Detection</h4><p name="55aa" id="55aa" class="graf graf--p graf-after--h4">First, a question that will help us build an intuition about the process of edge detection:</p><blockquote name="568e" id="568e" class="graf graf--blockquote graf-after--p">In terms of the mathematical information in an image (a matrix of data), what actually defines an edge?</blockquote><p name="3a3b" id="3a3b" class="graf graf--p graf-after--blockquote">To answer that question, let’s look closely at a lane marking that we hope to detect.</p><figure name="dbb8" id="dbb8" class="graf graf--figure graf--layoutOutsetLeft graf-after--p" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 525px; max-height: 325px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 62%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*v9y-rItOhCwh-u1NyZs3Cw.png" data-width="1142" data-height="708" data-action="zoom" data-action-value="1*v9y-rItOhCwh-u1NyZs3Cw.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1v9y-rItOhCwh-u1NyZs3Cw_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="45"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/600/1*v9y-rItOhCwh-u1NyZs3Cw.png" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1v9y-rItOhCwh-u1NyZs3Cw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/600/1*v9y-rItOhCwh-u1NyZs3Cw.png"></noscript></div></div><figcaption class="imageCaption">A lane marking with a highlighted section illustrating the gradient of an&nbsp;edge.</figcaption></figure><p name="2e31" id="2e31" class="graf graf--p graf-after--figure">If we pay close attention to the data surrounding this edge, it is fairly intuitive to conclude that edges are simply the <em class="markup--em markup--p-em">areas of an image where the color values change very quickly</em>. Therefore, detecting edges in an image becomes a mathematics problem of detecting any area where a pixel is a mismatch in color to all of its neighbors.</p><p name="3594" id="3594" class="graf graf--p graf-after--p">Fortunately for us, this mathematics problem is very solvable. In fact, computer scientist <a href="https://en.wikipedia.org/wiki/John_Canny" data-href="https://en.wikipedia.org/wiki/John_Canny" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">John F. Canny</a> invented <a href="https://en.wikipedia.org/wiki/Canny_edge_detector" data-href="https://en.wikipedia.org/wiki/Canny_edge_detector" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">an algorithm to do just that</a>, using <a href="https://en.wikipedia.org/wiki/Calculus_of_variations" data-href="https://en.wikipedia.org/wiki/Calculus_of_variations" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">calculus of variations</a> to achieve his solution. For those of you that have studied calculus before, it will be sensible that Canny Edge Detection essentially detects areas of the image that have a strong gradient in the image’s color function. Canny also adds a pair of intensity threshold parameters which indicate generally how strong an edge must be to be detected. See <a href="https://www.youtube.com/watch?v=sRFM5IEqR2w" data-href="https://www.youtube.com/watch?v=sRFM5IEqR2w" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank" savefrom_lm_index="0" savefrom_lm="1">this video for a good explanation</a><span style="padding: 0; margin: 0; margin-left: 5px;"><a href="http://savefrom.net/?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DsRFM5IEqR2w&amp;utm_source=ff-sf&amp;utm_medium=extensions&amp;utm_campaign=link_modifier" target="_blank" title="Get a direct link" style="background-image: url(&quot;data:image/gif;base64,R0lGODlhEAAQAOZ3APf39+Xl5fT09OPj4/Hx8evr6/3+/u7u7uDh4OPi497e3t7e3/z8/P79/X3GbuXl5ubl5eHg4WzFUfb39+Pj4lzGOV7LOPz7+/n6+vn5+ZTLj9/e387Ozt7f3/7+/vv7/ISbePn5+m/JV1nRKXmVbkCnKVrSLDqsCuDh4d/e3uDn3/z7/H6TdVeaV1uSW+bn5v39/eXm5eXm5kyHP/f39pzGmVy7J3yRd9/f3mLEKkXCHJbka2TVM5vaZn6Wdfn6+YG/c/r5+ZO/jeLi41aHTIeageLn4f39/vr6+kzNG2PVM5i+lomdf2CXYKHVmtzo2YXNeDqsBebl5uHh4HDKWN3g3kKqEH6WeZHTXIPKdnSPbv79/pfmbE7PHpe1l4O8dTO5DODg4VDLIlKUUtzo2J7SmEWsLlG4NJbFjkrJHP7+/VK5Nfz8+zmnC3KKa+Hg4OHh4Y63j/3+/eDg4Ojo6P///8DAwP///wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BAEAAHcALAAAAAAQABAAAAfWgHd2g4SFhYJzdYqLjIpzgx5bBgYwHg1Hk2oNDXKDFwwfDF5NLmMtcStsn4MhGT8YS04aGmU1QRhIGYMTADQAQlAODlloAMYTgwICRmRfVBISIkBPKsqDBAREZmcVFhYVayUz2IMHB1dWOmImI2lgUVrmgwUFLzdtXTxKSSduMfSD6Aik48MGlx05SAykM0gKhAAPAhTB0oNFABkPHg5KMIBCxzlMQFQZMGBIggSDpsCJgGDOmzkIUCAIM2dOhEEcNijQuQDHgg4KOqRYwMGOIENIB90JBAA7&quot;); background-repeat: no-repeat; width: 16px; height: 16px; display: inline-block; border: medium none; text-decoration: none; padding: 0px; position: relative;" savefrom_lm="1" savefrom_lm_is_link="1"></a></span>.</p><h4 name="8d67" id="8d67" class="graf graf--h4 graf-after--p">Grayscale Conversion and Canny Edge Detection</h4><p name="1b25" id="1b25" class="graf graf--p graf-after--h4">We don’t actually care about the colors of the picture at all, just the differences between their intensity values. In order to make the edge detection process simpler, we can convert the image into grayscale. This will remove color information and replace it with a single intensity value for each pixel of the image. Now our solution is to use Canny Edge Detection to find areas of the image that rapidly change over the intensity value.</p><p name="dd91" id="dd91" class="graf graf--p graf-after--p">For those of us that aren’t interested writing this algorithm ourselves, <a href="http://docs.opencv.org/trunk/da/d22/tutorial_py_canny.html" data-href="http://docs.opencv.org/trunk/da/d22/tutorial_py_canny.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">OpenCV ships with a single call implementation ready to use</a>. Let’s try running the Canny Edge Detection algorithm on our cropped image with some reasonable starter thresholds.</p><pre name="ef5b" id="ef5b" class="graf graf--pre graf-after--p">import matplotlib.pyplot as plt<br>import matplotlib.image as mpimg<br>import numpy as np<br>import cv2<br>import math</pre><pre name="7a33" id="7a33" class="graf graf--pre graf-after--pre">def region_of_interest(img, vertices):<br>    mask = np.zeros_like(img)<br>    channel_count = img.shape[2]<br>    match_mask_color = (255,) * channel_count<br>    cv2.fillPoly(mask, vertices, match_mask_color)<br>    masked_image = cv2.bitwise_and(img, mask)<br>    return masked_image</pre><pre name="26f6" id="26f6" class="graf graf--pre graf-after--pre">region_of_interest_vertices = [<br>    (0, height),<br>    (width / 2, height / 2),<br>    (width, height),<br>]</pre><pre name="bf41" id="bf41" class="graf graf--pre graf-after--pre">image = mpimg.imread('solidWhiteCurve.jpg')</pre><pre name="337d" id="337d" class="graf graf--pre graf-after--pre">cropped_image = region_of_interest(<br>    image,<br>    np.array([region_of_interest_vertices], np.int32),<br>)<br>plt.figure()<br>plt.imshow(cropped_image)</pre><pre name="0bbf" id="0bbf" class="graf graf--pre graf-after--pre"># Convert to grayscale here.<br>gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_RGB2GRAY)</pre><pre name="c9e4" id="c9e4" class="graf graf--pre graf-after--pre"># Call Canny Edge Detection here.<br>cannyed_image = cv2.Canny(gray_image, 100, 200)</pre><pre name="32b5" id="32b5" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(cannyed_image)</pre><pre name="5b70" id="5b70" class="graf graf--pre graf-after--pre">plt.show()</pre></div><div class="section-inner sectionLayout--outsetColumn"><figure name="116f" id="116f" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 279px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 27.900000000000002%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*oY2VO6ST1HejhdbqTlIP3A.png" data-width="2390" data-height="666" data-action="zoom" data-action-value="1*oY2VO6ST1HejhdbqTlIP3A.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1oY2VO6ST1HejhdbqTlIP3A.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="20"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*oY2VO6ST1HejhdbqTlIP3A.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*oY2VO6ST1HejhdbqTlIP3A.png"></noscript></div></div><figcaption class="imageCaption">Our cropped image with edges shown as a series of many single&nbsp;pixels.</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="896a" id="896a" class="graf graf--p graf-after--figure">We did it!, the image now contains only the single pixels which are indicative of an edge. But there’s a problem… We accidentally detected the edges of our cropped region of interest!</p><p name="ffee" id="ffee" class="graf graf--p graf-after--p">Not to worry, we can fix this problem by simply place the region of interest cropping after the Canny process in our pipeline. We also need to adjust the region of interest utility function to account for the fact that our image is now grayscale:</p><pre name="4202" id="4202" class="graf graf--pre graf-after--p">def region_of_interest(img, vertices):<br>    mask = np.zeros_like(img)</pre><pre name="d24e" id="d24e" class="graf graf--pre graf-after--pre">    match_mask_color = 255 # &lt;-- This line altered for grayscale.<br>    <br>    cv2.fillPoly(mask, vertices, match_mask_color)<br>    masked_image = cv2.bitwise_and(img, mask)<br>    return masked_image</pre><pre name="836d" id="836d" class="graf graf--pre graf-after--pre">region_of_interest_vertices = [<br>    (0, height),<br>    (width / 2, height / 2),<br>    (width, height),<br>]</pre><pre name="7dd2" id="7dd2" class="graf graf--pre graf-after--pre">image = mpimg.imread('solidWhiteCurve.jpg')</pre><pre name="22f1" id="22f1" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(image)</pre><pre name="5f5c" id="5f5c" class="graf graf--pre graf-after--pre">plt.show()</pre><pre name="b087" id="b087" class="graf graf--pre graf-after--pre">gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)<br>cannyed_image = cv2.Canny(gray_image, 100, 200)</pre><pre name="f767" id="f767" class="graf graf--pre graf-after--pre"># Moved the cropping operation to the end of the pipeline.<br>cropped_image = region_of_interest(<br>    cannyed_image,<br>    np.array([region_of_interest_vertices], np.int32)<br>)</pre><pre name="3bef" id="3bef" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(cropped_image)</pre><pre name="8703" id="8703" class="graf graf--pre graf-after--pre">plt.show()</pre><p name="6d52" id="6d52" class="graf graf--p graf-after--pre">Now let’s run our pipeline once more.</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="90ed" id="90ed" class="graf graf--figure graf--layoutOutsetCenter graf-after--p" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 270px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 27%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*_H6fK01cMRNanpuISluQ7w.png" data-width="2422" data-height="654" data-action="zoom" data-action-value="1*_H6fK01cMRNanpuISluQ7w.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1_H6fK01cMRNanpuISluQ7w.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="20"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*_H6fK01cMRNanpuISluQ7w.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*_H6fK01cMRNanpuISluQ7w.png"></noscript></div></div><figcaption class="imageCaption">Cropping after running Canny Edge Detection.</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><h3 name="ad0f" id="ad0f" class="graf graf--h3 graf-after--figure">Generating Lines from Edge&nbsp;Pixels</h3><p name="b3ad" id="b3ad" class="graf graf--p graf-after--h3">Perfect! This looks like a pretty good start for detecting the lane markings. It appears, in our output image, that the most prominent features of our processed image are indeed the lane markings. Now that we have the image processed down to a set of pixels representing edges, we need to link these pixels together to generate a list of lines. This is another problem that can be solved using some rather complicated mathematics theory. Don’t worry; we’ll stay on the surface level, again, unless you want to follow the links.</p><h4 name="1e81" id="1e81" class="graf graf--h4 graf-after--p">Mathematics of Line Detection</h4><p name="e8cd" id="e8cd" class="graf graf--p graf-after--h4">To get an intuition about the problem, let’s think about a similar question to the one that we posed about edge detection:</p><blockquote name="433d" id="433d" class="graf graf--blockquote graf-after--p">In terms of the mathematical information in an image (a matrix of data), what actually defines a line?</blockquote><p name="6ea9" id="6ea9" class="graf graf--p graf-after--blockquote">We have an image consisting of mostly blank pixels and a few scattered ‘edge pixels’ that have no known structure, but can easily be recognized as a line to a human observer. To answer our question, let’s take another look at the same lane marking from the edge detection example.</p><figure name="302d" id="302d" class="graf graf--figure graf--layoutOutsetLeft graf-after--p" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 525px; max-height: 313px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 59.599999999999994%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*7U04EK1WHgVBQkWkOkM2yA.png" data-width="1118" data-height="666" data-action="zoom" data-action-value="1*7U04EK1WHgVBQkWkOkM2yA.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/17U04EK1WHgVBQkWkOkM2yA.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="42"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/600/1*7U04EK1WHgVBQkWkOkM2yA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/600/1*7U04EK1WHgVBQkWkOkM2yA.png"></noscript></div></div><figcaption class="imageCaption">The same lane marking example, post edge detection. Line candidates marked in&nbsp;blue.</figcaption></figure><p name="e614" id="e614" class="graf graf--p graf-after--figure">If we pay close attention to a region that appears to be a line, we find that the edge pixels have something in common. We can imagine all the possible lines that pass through each pixel, but the points share only a few lines in common. These common lines can be thought of as candidates for the actual line (if it exists) that passes through all of the nearby edge pixels.</p><p name="fa31" id="fa31" class="graf graf--p graf-after--p">We have changed the difficult problem of interpreting many lines out of an entire image matrix of edge pixels and zeros into the much simpler problem of discovering lines which intersect multiple edge pixels at once. Although this is an easier problem, trial and error will not work. There are infinitely many lines that pass through each of the edge pixels, so we cannot simply test all of the lines to see if they match many of the pixels around a selected pixel. We can, however, use a mathematical trick to transform the input in such a way that there is a single solution for each line that we do want to discover.</p><p name="5a59" id="5a59" class="graf graf--p graf-after--p">The main concept we will be using here is called a <a href="https://en.wikipedia.org/wiki/Hough_transform" data-href="https://en.wikipedia.org/wiki/Hough_transform" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">Hough Transform</a>. Using a Hough Transform, we will transform all of our edge pixels into a different mathematical form. Once the transformation is complete, each edge pixel in “Image Space” will have become a line or curve in “Hough Space”. In Hough Space, each line represents a point from Image Space, and each point represents a line from Image Space. For a detailed explanation of this concept, check out <a href="https://www.youtube.com/watch?v=4zHbI-fFIlI" data-href="https://www.youtube.com/watch?v=4zHbI-fFIlI" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank" savefrom_lm_index="0" savefrom_lm="1">this video</a><span style="padding: 0; margin: 0; margin-left: 5px;"><a href="http://savefrom.net/?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4zHbI-fFIlI&amp;utm_source=ff-sf&amp;utm_medium=extensions&amp;utm_campaign=link_modifier" target="_blank" title="Get a direct link" style="background-image: url(&quot;data:image/gif;base64,R0lGODlhEAAQAOZ3APf39+Xl5fT09OPj4/Hx8evr6/3+/u7u7uDh4OPi497e3t7e3/z8/P79/X3GbuXl5ubl5eHg4WzFUfb39+Pj4lzGOV7LOPz7+/n6+vn5+ZTLj9/e387Ozt7f3/7+/vv7/ISbePn5+m/JV1nRKXmVbkCnKVrSLDqsCuDh4d/e3uDn3/z7/H6TdVeaV1uSW+bn5v39/eXm5eXm5kyHP/f39pzGmVy7J3yRd9/f3mLEKkXCHJbka2TVM5vaZn6Wdfn6+YG/c/r5+ZO/jeLi41aHTIeageLn4f39/vr6+kzNG2PVM5i+lomdf2CXYKHVmtzo2YXNeDqsBebl5uHh4HDKWN3g3kKqEH6WeZHTXIPKdnSPbv79/pfmbE7PHpe1l4O8dTO5DODg4VDLIlKUUtzo2J7SmEWsLlG4NJbFjkrJHP7+/VK5Nfz8+zmnC3KKa+Hg4OHh4Y63j/3+/eDg4Ojo6P///8DAwP///wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BAEAAHcALAAAAAAQABAAAAfWgHd2g4SFhYJzdYqLjIpzgx5bBgYwHg1Hk2oNDXKDFwwfDF5NLmMtcStsn4MhGT8YS04aGmU1QRhIGYMTADQAQlAODlloAMYTgwICRmRfVBISIkBPKsqDBAREZmcVFhYVayUz2IMHB1dWOmImI2lgUVrmgwUFLzdtXTxKSSduMfSD6Aik48MGlx05SAykM0gKhAAPAhTB0oNFABkPHg5KMIBCxzlMQFQZMGBIggSDpsCJgGDOmzkIUCAIM2dOhEEcNijQuQDHgg4KOqRYwMGOIENIB90JBAA7&quot;); background-repeat: no-repeat; width: 16px; height: 16px; display: inline-block; border: medium none; text-decoration: none; padding: 0px; position: relative;" savefrom_lm="1" savefrom_lm_is_link="1"></a></span>.</p><figure name="9b55" id="9b55" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 345px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 49.2%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*vPOSeUrdpDJ11q11TF_gpg.png" data-width="1922" data-height="946" data-action="zoom" data-action-value="1*vPOSeUrdpDJ11q11TF_gpg.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1vPOSeUrdpDJ11q11TF_gpg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="35"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*vPOSeUrdpDJ11q11TF_gpg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*vPOSeUrdpDJ11q11TF_gpg.png"></noscript></div></div><figcaption class="imageCaption">An illustration of an Image Space and it’s corresponding Hough Space (slope-intercept parameters). (<a href="https://alyssaq.github.io/2014/understanding-hough-transform/" data-href="https://alyssaq.github.io/2014/understanding-hough-transform/" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">Source</a>)</figcaption></figure><p name="85db" id="85db" class="graf graf--p graf-after--figure">We do not need to cover more detail about the mathematics involved in performing the Hough Transform. It is enough to know that this greatly simplifies the problem we need to solve.</p><p name="e89f" id="e89f" class="graf graf--p graf-after--p">To the point, we now do not need to solve for a line that intersects all nearby edge pixels. Instead, we can simply solve for the intersections between lines in Hough Space, and transform that intersection point back into Image Space to obtain a line which intersects enough edge pixels. The inputs to the Hough Transform can be varied to alter which lines are considered a real feature of the scene and which are just clutter.</p><h4 name="1bf7" id="1bf7" class="graf graf--h4 graf-after--p">Using Hough Transforms to Detect&nbsp;Lines</h4><p name="c245" id="c245" class="graf graf--p graf-after--h4">Fortunately for us, OpenCV ships with <a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html" data-href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">a function for generating Hough lines</a> from an image containing edge pixels. We will run this algorithm on our image with some reasonable parameters. This will generate a listing of all the lines believed by the Hough Transform to be a part of the scene and not a bit of clutter from the previous edge detection step.</p><pre name="790f" id="790f" class="graf graf--pre graf-after--p">...</pre><pre name="507d" id="507d" class="graf graf--pre graf-after--pre">image = mpimg.imread('solidWhiteCurve.jpg')</pre><pre name="82b7" id="82b7" class="graf graf--pre graf-after--pre">gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)<br>cannyed_image = cv2.Canny(gray_image, 200, 300)<br>cropped_image = region_of_interest(<br>    cannyed_image,<br>    np.array(<br>        [region_of_interest_vertices],<br>        np.int32<br>    ),<br>)</pre><pre name="2ca2" id="2ca2" class="graf graf--pre graf-after--pre">lines = cv2.HoughLinesP(<br>    cropped_image,<br>    rho=6,<br>    theta=np.pi / 60,<br>    threshold=160,<br>    lines=np.array([]),<br>    minLineLength=40,<br>    maxLineGap=25<br>)<br>print(lines)</pre><p name="f3e8" id="f3e8" class="graf graf--p graf-after--pre">The printout of the detected lines will be similar to below:</p><pre name="2a0d" id="2a0d" class="graf graf--pre graf-after--p">$ python load_image.py<br><br>[[[486 312 877 538]]</pre><pre name="d33b" id="d33b" class="graf graf--pre graf-after--pre">[[724 441 831 502]]</pre><pre name="5978" id="5978" class="graf graf--pre graf-after--pre">...</pre><pre name="bbe1" id="bbe1" class="graf graf--pre graf-after--pre">[[386 382 487 309]]]</pre><p name="c0cf" id="c0cf" class="graf graf--p graf-after--pre">Each line is represented by four numbers, which are the two endpoints of the detected line segment, like so</p><pre name="2b49" id="2b49" class="graf graf--pre graf-after--p">[x1, y1, x2, y2]</pre><p name="8e94" id="8e94" class="graf graf--p graf-after--pre">If we tweak the <code class="markup--code markup--p-code">rho</code>, <code class="markup--code markup--p-code">theta</code>, <code class="markup--code markup--p-code">threshold</code>, <code class="markup--code markup--p-code">minLineLength</code>, and <code class="markup--code markup--p-code">maxLineGap</code> parameters, we can detect many different kinds of lines within the image data. I encourage you to play with the values of these parameters at the end of this section of the article to see the effects that they have on line detection for yourself.</p><h4 name="a2bd" id="a2bd" class="graf graf--h4 graf-after--p">Rendering Detected Hough Lines as an&nbsp;Overlay</h4><p name="770e" id="770e" class="graf graf--p graf-after--h4">The last thing we will do with line detection is render the detected lines back onto the image itself, to give us a sense of the real features in the scene which are being detected. For this rendering, we’ll need to write another utility function:</p><pre name="e1a2" id="e1a2" class="graf graf--pre graf-after--p">def draw_lines(img, lines, color=[255, 0, 0], thickness=3):<br>    # If there are no lines to draw, exit.<br>        if lines is None:<br>            return</pre><pre name="139b" id="139b" class="graf graf--pre graf-after--pre">    # Make a copy of the original image.<br>    img = np.copy(img)</pre><pre name="2127" id="2127" class="graf graf--pre graf-after--pre">    # Create a blank image that matches the original in size.<br>    line_img = np.zeros(<br>        (<br>            img.shape[0],<br>            img.shape[1],<br>            3<br>        ),<br>        dtype=np.uint8,<br>    )</pre><pre name="86a4" id="86a4" class="graf graf--pre graf-after--pre">    # Loop over all lines and draw them on the blank image.<br>    for line in lines:<br>        for x1, y1, x2, y2 in line:<br>            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)</pre><pre name="2e34" id="2e34" class="graf graf--pre graf-after--pre">    # Merge the image with the lines onto the original.<br>    img = cv2.addWeighted(img, 0.8, line_image, 1.0, 0.0)</pre><pre name="6512" id="6512" class="graf graf--pre graf-after--pre">    # Return the modified image.<br>    return img</pre><p name="20aa" id="20aa" class="graf graf--p graf-after--pre">And then we’ll use this utility function inside of our processing script.</p><pre name="9c75" id="9c75" class="graf graf--pre graf-after--p">...</pre><pre name="347b" id="347b" class="graf graf--pre graf-after--pre">image = mpimg.imread('solidWhiteCurve.jpg')</pre><pre name="10b2" id="10b2" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(image)</pre><pre name="630b" id="630b" class="graf graf--pre graf-after--pre">plt.show()</pre><pre name="e818" id="e818" class="graf graf--pre graf-after--pre">gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)<br>cannyed_image = cv2.Canny(gray_image, 100, 200)<br>cropped_image = region_of_interest(<br>    cannyed_image,<br>    np.array(<br>        [region_of_interest_vertices],<br>        np.int32<br>    ),<br>)<br>lines = cv2.HoughLinesP(<br>    cropped_image,<br>    rho=6,<br>    theta=np.pi / 60,<br>    threshold=160,<br>    lines=np.array([]),<br>    minLineLength=40,<br>    maxLineGap=25<br>)</pre><pre name="1db8" id="1db8" class="graf graf--pre graf-after--pre">line_image = draw_lines(image, lines) # &lt;---- Add this call.</pre><pre name="1abe" id="1abe" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(line_image)</pre><pre name="9107" id="9107" class="graf graf--pre graf-after--pre">plt.show()</pre></div><div class="section-inner sectionLayout--outsetColumn"><figure name="0446" id="0446" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 279px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 27.900000000000002%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*RKs77nfqXQQ30WnvkAsHHw.png" data-width="2390" data-height="668" data-action="zoom" data-action-value="1*RKs77nfqXQQ30WnvkAsHHw.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1RKs77nfqXQQ30WnvkAsHHw.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="20"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*RKs77nfqXQQ30WnvkAsHHw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*RKs77nfqXQQ30WnvkAsHHw.png"></noscript></div></div><figcaption class="imageCaption">Output of our pipeline once we have rendered the detected lines back onto the original&nbsp;image.</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="2f1c" id="2f1c" class="graf graf--p graf-after--figure">Awesome! Now we have a copy of the original with the detected lines rendered as an overlay. This is very cool, but we want to distinguish the left and right lane lines independently and show a single line for each. In the next section, we’ll create a single line for each group of detected lane markings.</p><h3 name="57ad" id="57ad" class="graf graf--h3 graf-after--p">Creating a Single Left and Right Lane&nbsp;Line</h3><p name="6345" id="6345" class="graf graf--p graf-after--h3">The final step in our pipeline will be to create only one line for each of the groups of lines we found in the last step. This can be done by fitting a simple linear model to the various endpoints of the line segments in each group, then rendering a single overlay line on that linear model.</p><h4 name="df59" id="df59" class="graf graf--h4 graf-after--p">Grouping the Lines into Left and Right&nbsp;Groups</h4><p name="0d24" id="0d24" class="graf graf--p graf-after--h4">First, though, we need to determine which lines are in the left group, and which are in the right group.</p><p name="2d1d" id="2d1d" class="graf graf--p graf-after--p">For those who have taken algebra, one obvious difference between the two groups of line segments is the direction of their slope. The slope of a line measures the angle of that line, with a horizontal line having a slope of <code class="markup--code markup--p-code">0</code> and a vertical line having a slope of ∞. Almost all of the lines we will detect will have a slope somewhere in between these two values, because they are angled from the bottom of the image towards the center at the horizon.</p><p name="824b" id="824b" class="graf graf--p graf-after--p">Most importantly, the direction of a line’s slope describes whether the line is moving up or down as you travel along the line from left to right. A line with negative slope is said to be traveling downwards, while a line with positive slope is said to be traveling upwards. This is how slope direction works in normal coordinate systems where the origin is at the bottom left corner. In our coordinate system, however, the origin is in the top left corner, and so our slope directions will be reversed, with negative slopes traveling upwards and positive slopes traveling downwards.</p><p name="17b9" id="17b9" class="graf graf--p graf-after--p">In our images, the left lane markings all have a negative slope, meaning the lines travel upwards towards the horizon as we move from left to right along the lines. On the other hand, all of our right lane markings have a positive slope, traveling downwards towards the bottom of the image as we move along them from left to right. This will be the distinction we use to group the left and right lines. Furthermore, the lane markings appear extreme in slope, so we will not consider any line with a slope absolute value less than <code class="markup--code markup--p-code">0.5</code>. This means that we’ll reject any line which doesn’t move quickly towards the horizon or the bottom of the image, leaving only lines which are nearer to vertical than horizontal.</p><pre name="cb75" id="cb75" class="graf graf--pre graf-after--p">...</pre><pre name="e44b" id="e44b" class="graf graf--pre graf-after--pre">left_line_x = []<br>left_line_y = []<br>right_line_x = []<br>right_line_y = []</pre><pre name="c4ac" id="c4ac" class="graf graf--pre graf-after--pre">for line in lines:<br>    for x1, y1, x2, y2 in line:<br>        slope = (y2 - y1) / (x2 - x1) # &lt;-- Calculating the slope.<br>        if math.fabs(slope) &lt; 0.5: # &lt;-- Only consider extreme slope<br>            continue<br>        if slope &lt;= 0: # &lt;-- If the slope is negative, left group.<br>            left_line_x.extend([x1, x2])<br>            left_line_y.extend([y1, y2])<br>        else: # &lt;-- Otherwise, right group.<br>            right_line_x.extend([x1, x2])<br>            right_line_y.extend([y1, y2])</pre><p name="4fcf" id="4fcf" class="graf graf--p graf-after--pre">In this snippet, we loop over all of the lines we’ve detected and calculate their slope. If the slope is not extreme enough to be a lane marking edge, we will not consider it at all, and continue the loop without handling that line. If the slope is negative, the line belongs to the left lane markings group. If the slope is positive, the line belongs to the right group. To add a line to either group, we add the various <code class="markup--code markup--p-code">x</code> and <code class="markup--code markup--p-code">y</code> endpoint coordinates to lists for each side.</p><h4 name="6224" id="6224" class="graf graf--h4 graf-after--p">Creating a Single Linear Representation of each Line&nbsp;Group</h4><p name="3971" id="3971" class="graf graf--p graf-after--h4">The second challenge in our single line creation problem is to average the lines in each group into a single line that fits pretty closely in orientation and location in the image.</p><p name="2fff" id="2fff" class="graf graf--p graf-after--p">Think about known values that we can work from to generate the left and right lane lines. Two known values are the <code class="markup--code markup--p-code">y</code> values for the top and bottom endpoints of the segments, which both lane lines will hold in common. We want the lines to begin at the bottom of the image, and travel along the lane markings towards the horizon, ending just below the horizon. The problem then becomes an exercise of finding the correct <code class="markup--code markup--p-code">x</code> values for each point of the two line segments.</p><pre name="b295" id="b295" class="graf graf--pre graf-after--p">min_y = image.shape[0] * (3 / 5) # &lt;-- Just below the horizon<br>max_y = image.shape[0] # &lt;-- The bottom of the image</pre><p name="4712" id="4712" class="graf graf--p graf-after--pre">In order to find the correct <code class="markup--code markup--p-code">x</code> values for the top and bottom points of each line, we can develop two functions <code class="markup--code markup--p-code">f(y) = x</code> that define the left and right lines. Then we can feed the two common <code class="markup--code markup--p-code">y</code> values into the functions to find the <code class="markup--code markup--p-code">x</code> values that complete our endpoint coordinates. This function needs to be a linear fit to the coordinates in each group in order to average our detected lines, and fortunately numpy provides some functions to do it!</p><p name="586c" id="586c" class="graf graf--p graf-after--p">The <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html" data-href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">polyfit</a> and <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.poly1d.html" data-href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.poly1d.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">poly1d</a> operations can generate a linear function that match the two given spaces (<code class="markup--code markup--p-code">x</code> and <code class="markup--code markup--p-code">y</code>) for each group.</p><pre name="cb73" id="cb73" class="graf graf--pre graf-after--p">...</pre><pre name="aeee" id="aeee" class="graf graf--pre graf-after--pre">poly_left = np.poly1d(np.polyfit(<br>    left_line_y,<br>    left_line_x,<br>    deg=1<br>))</pre><pre name="63a1" id="63a1" class="graf graf--pre graf-after--pre">left_x_start = int(poly_left(max_y))<br>left_x_end = int(poly_left(min_y))</pre><pre name="d11e" id="d11e" class="graf graf--pre graf-after--pre">poly_right = np.poly1d(np.polyfit(<br>    right_line_y,<br>    right_line_x,<br>    deg=1<br>))</pre><pre name="8f10" id="8f10" class="graf graf--pre graf-after--pre">right_x_start = int(poly_right(max_y))<br>right_x_end = int(poly_right(min_y))</pre><p name="804f" id="804f" class="graf graf--p graf-after--pre">Now we can use these lines as our input to the <code class="markup--code markup--p-code">draw_lines</code> function in our pipeline:</p><pre name="163b" id="163b" class="graf graf--pre graf-after--p">...</pre><pre name="8265" id="8265" class="graf graf--pre graf-after--pre">image = mpimg.imread('solidWhiteCurve.jpg')</pre><pre name="9bac" id="9bac" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(image)</pre><pre name="da52" id="da52" class="graf graf--pre graf-after--pre">gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)<br>cannyed_image = cv2.Canny(gray_image, 100, 200)<br>cropped_image = region_of_interest(<br>    cannyed_image,<br>    np.array(<br>        [region_of_interest_vertices],<br>        np.int32<br>    ),<br>)<br>lines = cv2.HoughLinesP(<br>    cropped_image,<br>    rho=6,<br>    theta=np.pi / 60,<br>    threshold=160,<br>    lines=np.array([]),<br>    minLineLength=40,<br>    maxLineGap=25<br>)</pre><pre name="1271" id="1271" class="graf graf--pre graf-after--pre">left_line_x = []<br>left_line_y = []<br>right_line_x = []<br>right_line_y = []</pre><pre name="0919" id="0919" class="graf graf--pre graf-after--pre">for line in lines:<br>    for x1, y1, x2, y2 in line:<br>        slope = (y2 - y1) / (x2 - x1) # &lt;-- Calculating the slope.<br>        if math.fabs(slope) &lt; 0.5: # &lt;-- Only consider extreme slope<br>            continue<br>        if slope &lt;= 0: # &lt;-- If the slope is negative, left group.<br>            left_line_x.extend([x1, x2])<br>            left_line_y.extend([y1, y2])<br>        else: # &lt;-- Otherwise, right group.<br>            right_line_x.extend([x1, x2])<br>            right_line_y.extend([y1, y2])</pre><pre name="d7f9" id="d7f9" class="graf graf--pre graf-after--pre">min_y = image.shape[0] * (3 / 5) # &lt;-- Just below the horizon<br>max_y = image.shape[0] # &lt;-- The bottom of the image</pre><pre name="73d3" id="73d3" class="graf graf--pre graf-after--pre">poly_left = np.poly1d(np.polyfit(<br>    left_line_y,<br>    left_line_x,<br>    deg=1<br>))</pre><pre name="fb1d" id="fb1d" class="graf graf--pre graf-after--pre">left_x_start = int(poly_left(max_y))<br>left_x_end = int(poly_left(min_y))</pre><pre name="d274" id="d274" class="graf graf--pre graf-after--pre">poly_right = np.poly1d(np.polyfit(<br>    right_line_y,<br>    right_line_x,<br>    deg=1<br>))</pre><pre name="e97e" id="e97e" class="graf graf--pre graf-after--pre">right_x_start = int(poly_right(max_y))<br>right_x_end = int(poly_right(min_y))</pre><pre name="659e" id="659e" class="graf graf--pre graf-after--pre">line_image = draw_lines(<br>    image,<br>    [[<br>        [left_x_start, max_y, left_x_end, min_y],<br>        [right_x_start, max_y, right_x_end, min_y],<br>    ]],<br>    thickness=5,<br>)</pre><pre name="fdf1" id="fdf1" class="graf graf--pre graf-after--pre">plt.figure()<br>plt.imshow(line_image)</pre><pre name="caaf" id="caaf" class="graf graf--pre graf-after--pre">plt.show()</pre></div><div class="section-inner sectionLayout--outsetColumn"><figure name="7426" id="7426" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 263px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 26.3%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*5HEIDnC0kxSW1F9r88S46A.png" data-width="2368" data-height="622" data-action="zoom" data-action-value="1*5HEIDnC0kxSW1F9r88S46A.png" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/15HEIDnC0kxSW1F9r88S46A.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="17"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*5HEIDnC0kxSW1F9r88S46A.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*5HEIDnC0kxSW1F9r88S46A.png"></noscript></div></div><figcaption class="imageCaption">The final overlay of our two single lane&nbsp;lines.</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="4a8c" id="4a8c" class="graf graf--p graf-after--figure">We did it!</p><h3 name="7332" id="7332" class="graf graf--h3 graf-after--p">Level Up: Annotate a&nbsp;Video</h3><p name="a749" id="a749" class="graf graf--p graf-after--h3">Now that we have an image processing pipeline to work with, we can actually apply the same techniques to a video to overlay our lane lines upon the video! We’ll use <a href="https://github.com/udacity/CarND-LaneLines-P1/blob/master/test_videos/solidWhiteRight.mp4" data-href="https://github.com/udacity/CarND-LaneLines-P1/blob/master/test_videos/solidWhiteRight.mp4" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">a test video which contains the image we have been working with above</a>.</p><p name="5600" id="5600" class="graf graf--p graf-after--p">First, let’s put all of our current work into a defined function named <code class="markup--code markup--p-code">pipeline()</code>.</p><pre name="e4d6" id="e4d6" class="graf graf--pre graf-after--p">import matplotlib.pyplot as plt<br>import matplotlib.image as mpimg<br>import numpy as np<br>import cv2<br>import math</pre><pre name="003e" id="003e" class="graf graf--pre graf-after--pre">def region_of_interest(img, vertices):<br>    mask = np.zeros_like(img)<br>    match_mask_color = 255<br>    cv2.fillPoly(mask, vertices, match_mask_color)<br>    masked_image = cv2.bitwise_and(img, mask)<br>    return masked_image</pre><pre name="cb3f" id="cb3f" class="graf graf--pre graf-after--pre">def draw_lines(img, lines, color=[255, 0, 0], thickness=3):<br>    line_img = np.zeros(<br>        (<br>            img.shape[0],<br>            img.shape[1],<br>            3<br>        ),<br>        dtype=np.uint8<br>    )<br>    img = np.copy(img)<br>    if lines is None:<br>        return</pre><pre name="c67b" id="c67b" class="graf graf--pre graf-after--pre">    for line in lines:<br>        for x1, y1, x2, y2 in line:<br>            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)</pre><pre name="81e1" id="81e1" class="graf graf--pre graf-after--pre">    img = cv2.addWeighted(img, 0.8, line_img, 1.0, 0.0)</pre><pre name="c00d" id="c00d" class="graf graf--pre graf-after--pre">    return img</pre><pre name="093f" id="093f" class="graf graf--pre graf-after--pre">def pipeline(image):<br>    """<br>    An image processing pipeline which will output<br>    an image with the lane lines annotated.<br>    """</pre><pre name="c78d" id="c78d" class="graf graf--pre graf-after--pre">    height = image.shape[0]<br>    width = image.shape[1]<br>    region_of_interest_vertices = [<br>        (0, height),<br>        (width / 2, height / 2),<br>        (width, height),<br>    ]</pre><pre name="bb5e" id="bb5e" class="graf graf--pre graf-after--pre">    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)</pre><pre name="7b50" id="7b50" class="graf graf--pre graf-after--pre">    cannyed_image = cv2.Canny(gray_image, 100, 200)<br> <br>    cropped_image = region_of_interest(<br>        cannyed_image,<br>        np.array(<br>            [region_of_interest_vertices],<br>            np.int32<br>        ),<br>    )<br> <br>    lines = cv2.HoughLinesP(<br>        cropped_image,<br>        rho=6,<br>        theta=np.pi / 60,<br>        threshold=160,<br>        lines=np.array([]),<br>        minLineLength=40,<br>        maxLineGap=25<br>    )<br> <br>    left_line_x = []<br>    left_line_y = []<br>    right_line_x = []<br>    right_line_y = []<br> <br>    for line in lines:<br>        for x1, y1, x2, y2 in line:<br>            slope = (y2 - y1) / (x2 - x1)<br>    if math.fabs(slope) &lt; 0.5:<br>        continue<br>    if slope &lt;= 0:<br>        left_line_x.extend([x1, x2])<br>        left_line_y.extend([y1, y2])<br>    else:<br>        right_line_x.extend([x1, x2])<br>        right_line_y.extend([y1, y2])</pre><pre name="6d2c" id="6d2c" class="graf graf--pre graf-after--pre">    min_y = int(image.shape[0] * (3 / 5))<br>    max_y = int(image.shape[0])</pre><pre name="852f" id="852f" class="graf graf--pre graf-after--pre">    poly_left = np.poly1d(np.polyfit(<br>        left_line_y,<br>        left_line_x,<br>        deg=1<br>    ))<br> <br>    left_x_start = int(poly_left(max_y))<br>    left_x_end = int(poly_left(min_y))<br> <br>    poly_right = np.poly1d(np.polyfit(<br>        right_line_y,<br>        right_line_x,<br>       deg=1<br>    ))<br> <br>    right_x_start = int(poly_right(max_y))<br>    right_x_end = int(poly_right(min_y))</pre><pre name="088b" id="088b" class="graf graf--pre graf-after--pre">    line_image = draw_lines(<br>        image,<br>        [[<br>            [left_x_start, max_y, left_x_end, min_y],<br>            [right_x_start, max_y, right_x_end, min_y],<br>        ]],<br>        thickness=5,<br>    )</pre><pre name="5473" id="5473" class="graf graf--pre graf-after--pre">    return line_image</pre><p name="de7f" id="de7f" class="graf graf--p graf-after--pre">And then we can write a video processing pipeline:</p><pre name="4128" id="4128" class="graf graf--pre graf-after--p">from moviepy.editor import VideoFileClip<br>from IPython.display import HTML</pre><pre name="96ea" id="96ea" class="graf graf--pre graf-after--pre">white_output = 'solidWhiteRight_output.mp4'<br>clip1 = VideoFileClip("solidWhiteRight_input.mp4")<br>white_clip = clip1.fl_image(pipeline)<br>white_clip.write_videofile(white_output, audio=False)</pre><p name="4fed" id="4fed" class="graf graf--p graf-after--pre">After the video is finished processing, you should be able to open your video and have it match very nearly to the one below. Congratulations!</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="3a22" id="3a22" class="graf graf--figure graf--iframe graf--layoutOutsetCenter graf-after--p" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia is-canvasLoaded" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/resize_003.jpeg" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="56"></canvas><div class="iframeContainer"><iframe data-width="854" data-height="480" data-src="/media/1261e5fbaff3798b46e4cf21ee5a8f53?postId=bfeb6ae54ec0" data-media-id="1261e5fbaff3798b46e4cf21ee5a8f53" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMR5W03V-ldY%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" width="980" height="551" frameborder="0"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME data-width="854" data-height="480" width="980" height="551" src="/media/1261e5fbaff3798b46e4cf21ee5a8f53?postId=bfeb6ae54ec0" data-media-id="1261e5fbaff3798b46e4cf21ee5a8f53" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMR5W03V-ldY%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="10fd" id="10fd" class="graf graf--p graf-after--figure">If you are interested in tinkering with this project further, you can visit the <a href="https://github.com/udacity/CarND-LaneLines-P1" data-href="https://github.com/udacity/CarND-LaneLines-P1" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">Udacity project repository here</a>.</p><p name="078a" id="078a" class="graf graf--p graf-after--p">I’ll leave you with some additional videos that I tested my pipeline on.</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="f83a" id="f83a" class="graf graf--figure graf--iframe graf--layoutOutsetCenter graf-after--p" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia is-canvasLoaded" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/resize_002.jpeg" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="56"></canvas><div class="iframeContainer"><iframe data-width="854" data-height="480" data-src="/media/8916de5c7d88fba75453c7e060d4ae2c?postId=bfeb6ae54ec0" data-media-id="8916de5c7d88fba75453c7e060d4ae2c" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FJF4f31qK_og%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" width="980" height="551" frameborder="0"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME data-width="854" data-height="480" width="980" height="551" src="/media/8916de5c7d88fba75453c7e060d4ae2c?postId=bfeb6ae54ec0" data-media-id="8916de5c7d88fba75453c7e060d4ae2c" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FJF4f31qK_og%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div></figure><figure name="9bcc" id="9bcc" class="graf graf--figure graf--iframe graf--layoutOutsetCenter graf-after--figure graf--trailing" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.2%;"></div><div class="progressiveMedia js-progressiveMedia is-canvasLoaded" data-scroll="native"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/resize.jpeg" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="56"></canvas><div class="iframeContainer"><iframe data-width="854" data-height="480" data-src="/media/ee953b2ba3e4357606c49e2bcca335d9?postId=bfeb6ae54ec0" data-media-id="ee953b2ba3e4357606c49e2bcca335d9" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FyvyarXjTu9A%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" width="980" height="551" frameborder="0"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME data-width="854" data-height="480" width="980" height="551" src="/media/ee953b2ba3e4357606c49e2bcca335d9?postId=bfeb6ae54ec0" data-media-id="ee953b2ba3e4357606c49e2bcca335d9" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FyvyarXjTu9A%2Fhqdefault.jpg&amp;key=4fce0568f2ce49e8b54624ef71a8a5bd" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div></figure></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link" href="https://medium.com/tag/machine-learning?source=post" data-action-source="post">Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://medium.com/tag/udacity?source=post" data-action-source="post">Udacity</a></li><li><a class="link u-baseColor--link" href="https://medium.com/tag/self-driving-cars?source=post" data-action-source="post">Self Driving Cars</a></li><li><a class="link u-baseColor--link" href="https://medium.com/tag/autonomous-cars?source=post" data-action-source="post">Autonomous Cars</a></li><li><a class="link u-baseColor--link" href="https://medium.com/tag/opencv?source=post" data-action-source="post">Opencv</a></li></ul></div></div></div><section class="uiScale uiScale-ui--small uiScale-caption--regular u-borderTopLightest u-marginTop10 u-paddingTop20"><div class="ui-h3 u-textColorDarker u-fontSize22">Like what you read? Give Matt Hardwick a round of applause.</div><p class="ui-body u-marginBottom20 u-textColorDark u-fontSize16">From a quick cheer to a standing ovation, clap to show how much you enjoyed this story.</p></section><div class="postActions js-postActionsFooter"><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter u-width60" data-post-id="bfeb6ae54ec0" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----bfeb6ae54ec0---------------------clap_footer"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboarding" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/bfeb6ae54ec0" data-action-source="post_actions_footer-----bfeb6ae54ec0---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="bfeb6ae54ec0"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft10"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="bfeb6ae54ec0">159</button></span></div></div><div class="buttonSet u-flex0"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="scroll-to-responses" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal" data-action="scroll-to-responses">3</button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg></span></button><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="5736bd18104c"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/5736bd18104c" data-action-source="footer_card-5736bd18104c-------------------------follow_footer"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://medium.com/@mrhwick?source=footer_card" title="Go to the profile of Matt Hardwick" aria-label="Go to the profile of Matt Hardwick" data-action-source="footer_card" data-user-id="5736bd18104c" dir="auto"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/0w9URdmuBdJxuElHz_003.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Matt Hardwick"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://medium.com/@mrhwick" property="cc:attributionName" title="Go to the profile of Matt Hardwick" aria-label="Go to the profile of Matt Hardwick" rel="author cc:attributionUrl" data-user-id="5736bd18104c" dir="auto">Matt Hardwick</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Software Engineer. Computer Scientist. Fascinated with the world at large and my place in it.</p></div></li></div></div></div><div class="js-postFooterPlacements"><div class="streamItem streamItem--placementCardGrid js-streamItem"><div class="u-clearfix u-backgroundGrayLightest"><div class="row u-marginAuto u-maxWidth1000 u-paddingTop30 u-paddingBottom40"><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="524caca13b2b" data-source="placement_card_footer_grid---------0-44" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://medium.com/@mrhwick/traffic-sign-classification-with-tensorflow-524caca13b2b?source=placement_card_footer_grid---------0-44" data-action-source="placement_card_footer_grid---------0-44"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*MUMlpxz3NTrSPZJL4lszbA.png&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://medium.com/@mrhwick/traffic-sign-classification-with-tensorflow-524caca13b2b?source=placement_card_footer_grid---------0-44" data-action-source="placement_card_footer_grid---------0-44"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Matt Hardwick</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Traffic Sign Classification with TensorFlow</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@mrhwick" data-action="show-user-card" data-action-value="5736bd18104c" data-action-type="hover" data-user-id="5736bd18104c" dir="auto"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/0w9URdmuBdJxuElHz_002.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Matt Hardwick"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://medium.com/@mrhwick?source=placement_card_footer_grid---------0-44" data-action="show-user-card" data-action-source="placement_card_footer_grid---------0-44" data-action-value="5736bd18104c" data-action-type="hover" data-user-id="5736bd18104c" dir="auto">Matt Hardwick</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="22 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="524caca13b2b" data-is-label-padded="true" data-source="placement_card_footer_grid-----524caca13b2b----0-44----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/524caca13b2b" data-action-source="placement_card_footer_grid-----524caca13b2b----0-44----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="524caca13b2b">3</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/524caca13b2b" data-action-source="placement_card_footer_grid-----524caca13b2b----0-44----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="aea1752b1ad0" data-source="placement_card_footer_grid---------1-43" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://medium.com/@andrewng/self-driving-cars-are-here-aea1752b1ad0?source=placement_card_footer_grid---------1-43" data-action-source="placement_card_footer_grid---------1-43"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*Rkd4uOPkU446v_QbcY-3lQ.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://medium.com/@andrewng/self-driving-cars-are-here-aea1752b1ad0?source=placement_card_footer_grid---------1-43" data-action-source="placement_card_footer_grid---------1-43"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">Also tagged Self Driving Cars</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Self-driving cars are here</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@andrewng" data-action="show-user-card" data-action-value="592ce2a67248" data-action-type="hover" data-user-id="592ce2a67248" dir="auto"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/19xfnIxWCa313OO4OaT-v2w.png" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Andrew Ng"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://medium.com/@andrewng?source=placement_card_footer_grid---------1-43" data-action="show-user-card" data-action-source="placement_card_footer_grid---------1-43" data-action-value="592ce2a67248" data-action-type="hover" data-user-id="592ce2a67248" dir="auto">Andrew Ng</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="6 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="aea1752b1ad0" data-is-label-padded="true" data-source="placement_card_footer_grid-----aea1752b1ad0----1-43----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/aea1752b1ad0" data-action-source="placement_card_footer_grid-----aea1752b1ad0----1-43----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="aea1752b1ad0">9.96K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/aea1752b1ad0" data-action-source="placement_card_footer_grid-----aea1752b1ad0----1-43----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="7d9ae8df1c58" data-source="placement_card_footer_grid---------2-60" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://codeburst.io/self-driving-cars-implementing-real-time-traffic-light-detection-and-classification-in-2017-7d9ae8df1c58?source=placement_card_footer_grid---------2-60" data-action-source="placement_card_footer_grid---------2-60"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*cWpuOWiqqWs2mGJ7n8-zRw.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://codeburst.io/self-driving-cars-implementing-real-time-traffic-light-detection-and-classification-in-2017-7d9ae8df1c58?source=placement_card_footer_grid---------2-60" data-action-source="placement_card_footer_grid---------2-60"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">Related reads</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Self-Driving Cars: Implementing Real-Time Traffic Light Detection and Classification in 2017</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://codeburst.io/@anthony_sarkis" data-action="show-user-card" data-action-value="149e0bf17d7b" data-action-type="hover" data-user-id="149e0bf17d7b" data-collection-slug="codeburst" dir="auto"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/1rVsnDz1G_GcCB3tt_wD9lw.png" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Anthony Sarkis"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://codeburst.io/@anthony_sarkis?source=placement_card_footer_grid---------2-60" data-action="show-user-card" data-action-source="placement_card_footer_grid---------2-60" data-action-value="149e0bf17d7b" data-action-type="hover" data-user-id="149e0bf17d7b" data-collection-slug="codeburst" dir="auto">Anthony Sarkis</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="6 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="7d9ae8df1c58" data-is-label-padded="true" data-source="placement_card_footer_grid-----7d9ae8df1c58----2-60----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/7d9ae8df1c58" data-action-source="placement_card_footer_grid-----7d9ae8df1c58----2-60----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="7d9ae8df1c58">471</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/7d9ae8df1c58" data-action-source="placement_card_footer_grid-----7d9ae8df1c58----2-60----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div></div></div></div></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_5"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream-editor cardChromeless u-marginBottom20 u-paddingLeft20 u-paddingRight20 js-responsesStreamEditor"><div class="u-paddingTop30 u-paddingBottom30 u-paddingLeft0 u-paddingRight0 u-borderBottomLightest js-responsesLoggedOutPrompt"><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--withIconAndLabel button--loggedOutPrompt" data-action="sign-up-prompt" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0#--respond" data-skip-onboarding="true" data-action-source="logged_out_response_prompt--------------------------respond_box"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span><span class="button-label  js-buttonLabel">Write a response…</span></button></div></div><div class="responsesStream js-responsesStream"></div><div class="container js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-sizeFullWidth u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1000 js-postLeftSidebar"><div class="u-foreground u-top0 u-fixed u-sm-hide u-marginLeftNegative12 js-postShareWidget u-transition--fadeIn300" data-scroll="fixed" style="transform: translateY(150px);"><ul><li class="u-textAlignCenter u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexColumn u-marginBottom10 u-width60" data-post-id="bfeb6ae54ec0" data-is-icon-29px="true" data-is-vertical="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_share_widget-----bfeb6ae54ec0---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/bfeb6ae54ec0" data-action-source="post_share_widget-----bfeb6ae54ec0---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="bfeb6ae54ec0"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-flexOrderNegative1 u-height20 u-marginBottom7"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-block u-marginAuto" data-action="show-recommends" data-action-value="bfeb6ae54ec0">159</button></span></div></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_share_widget"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg></span></button></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_share_widget"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg></span></button></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/bfeb6ae54ec0" data-action-source="post_share_widget-----bfeb6ae54ec0---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li></ul></div></aside><div class="u-fixed u-bottom0 u-sizeFullWidth u-backgroundWhite u-boxShadowTop u-borderBox u-paddingTop10 u-paddingBottom10 u-zIndexMetabar u-xs-paddingLeft10 u-xs-paddingRight10 js-stickyFooter"><div class="u-maxWidth700 u-marginAuto u-flexCenter"><div class="u-fontSize16 u-flex1 u-flexCenter"><div class="u-flex0 u-inlineBlock u-paddingRight20 u-xs-paddingRight10"><a class="link u-baseColor--link avatar u-inline" href="https://medium.com/@mrhwick" data-action="show-user-card" data-action-value="5736bd18104c" data-action-type="hover" data-user-id="5736bd18104c" dir="auto"><img src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/0w9URdmuBdJxuElHz.jpeg" class="avatar-image avatar-image--smaller" alt="Go to the profile of Matt Hardwick"></a></div><div class="u-flex1 u-inlineBlock"><div class="u-xs-hide">Never miss a story from<strong> Matt Hardwick</strong>, when you sign up for Medium. <a class="link u-baseColor--link link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@Medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg" data-action-source="sticky_footer">Learn more</a></div><div class="u-xs-show">Never miss a story from<strong> Matt Hardwick</strong></div></div></div><div class="u-marginLeft50 u-xs-marginAuto"><span class="followState js-followState" data-user-id="5736bd18104c"><button class="button u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-uiTextSemibold u-textUppercase u-fontSize12" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-action-source="sticky_footer"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary is-active u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton u-uiTextSemibold u-textUppercase u-fontSize12" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/5736bd18104c" data-action-source="sticky_footer-5736bd18104c-------------------------follow_metabar"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Get updates</span></button></span></div></div></div><div class="highlightMenu" data-action-scope="_actionscope_3"><div class="highlightMenu-inner"><div class="buttonSet"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu u-accentColor--highlightStrong js-highlightMenuQuoteButton" data-action="sign-up-prompt" data-sign-in-action="quote" data-requires-token="true" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-skip-onboarding="true" data-redirect-type="quote" data-action-source="quote_menu--------------------------highlight_text"><span class="svgIcon svgIcon--highlighter svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M13.7 15.964l5.204-9.387-4.726-2.62-5.204 9.387 4.726 2.62zm-.493.885l-1.313 2.37-1.252.54-.702 1.263-3.796-.865 1.228-2.213-.202-1.35 1.314-2.37 4.722 2.616z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="quote-respond" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-skip-onboarding="true" data-action-source="quote_menu--------------------------respond_text"><span class="svgIcon svgIcon--responseFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19.074 21.117c-1.244 0-2.432-.37-3.532-1.096a7.792 7.792 0 0 1-.703-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.662 0 8.457 3.5 8.457 7.803 0 2.058-.85 3.984-2.403 5.448.023.17.06.35.118.55.192.69.537 1.38 1.026 2.04.15.21.172.48.058.7a.686.686 0 0 1-.613.38h-.03z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="twitter" data-action-source="quote_menu" data-skip-onboarding="true"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></button><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="highlight" data-redirect="https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0" data-skip-onboarding="true" data-action-source="quote_menu--------------------------privatenote_text"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://medium.com","buildLabel":"33744-8f43eb9","currentUser":{"userId":"lo_j4q52oOnOkJ1","isVerified":false,"subscriberEmail":"","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":false,"hightowerLastLockedAt":0},"currentUserHasUnverifiedEmail":false,"isAuthenticated":false,"isCurrentUserVerified":false,"language":"en-us","mediumTwitterScreenName":"medium","miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.rOtrDLm5t4ommEPkcDnhGA.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.iid8_9a5a4EFR4Vumk2yLg.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.6VSlQb5qi54Ed6I9IyIC8A.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.zm03m_SabKysM9fEyvavFg.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle._xIeyP-cGs_BJislZf82Uw.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.IHEgpwhMd8e0VibkwbCzqA.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.wwfmvscUwM-OyaUt_nAE7g.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.MuMJRvOwSjcGdDg_kUyPPw.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.9iS2-LN2PNLogXPPG46D6Q.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.4IMErd4RFwupX4vvI36gCg.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.FiymVWIkZoH2slhB2fpczA.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":true,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1526497275448:28109785da0c","useragent":{"browser":"firefox","family":"firefox","os":"","version":50,"supportsDesktopEdit":true,"supportsInteract":true,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":true,"isTier1":true,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":true,"supportsVhUnits":true,"ruinsViewportSections":false,"supportsHtml5Video":true,"supportsMagicUnderlines":true,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":true,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":true,"supportsVideoSections":true,"emojiSupportLevel":1,"isSearchBot":false,"isSyndicationBot":false,"supportsScrollableMetabar":true},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv","signup_services":"twitter,facebook,google,email,google-fastidv","android_rating_prompt_recommend_threshold":5,"google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"enable_export_members":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","enable_sms":true,"disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"disable_followed_tag_fan_out":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"enable_sequence_carousel":true,"enable_multirecommends":true,"enable_post_monger_v2":true,"enable_post_monger_v3":true,"enable_hightower_editor_copy_v2":true,"enable_user_post_metering":true,"max_premium_content_per_user_under_metering":3,"tag_intercom_user_on_metering_count":3,"enable_topic_writer_onboarding":true,"enable_strong_graph_chp_reorder":true,"enable_unsplash_images":true,"enable_top_stories_for_you":true,"enable_ios_member_post_labeling":true,"enable_lite_profile":true,"enable_li_search_collection":true,"enable_gosocial_aurora_shadow_reads":true,"enable_homepage_remodel":true,"enable_signin_wall_custom_domain":true,"enable_standalone_profile_edit_page":true,"enable_standalone_user_follow_pages":true,"enable_post_footer_copy":true,"app_download_email_template":"control","enable_topic_lifecycle_email":true,"enable_marketing_emails":true,"enable_curation_post_locking":true,"ios_hide_avatars_on_home":true,"raise_editors_picks_digest":"control","android_disable_author_avatars":true,"enable_persistent_user_id_for_dnt":true,"enable_truncated_rss_for_tags_and_topics":true,"enable_ios_related_reads_api_change":true,"enable_ios_related_reads_ui_large":true,"enable_ios_responses_collapsed":true,"enable_latin_font_subset":true,"enable_creator_landing_updates":true,"enable_meter_subject_line_test":true},"xsrfToken":"","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":true,"algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/si/latin/e/sb/latin/e/sbi/latin/e/ssr/latin/e/ssb/latin/e/ai/latin/e/mkt/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/e/mkt/latin/m2.css"},{"id":12,"url":"https://glyph.medium.com/css/e/sr/latin/e/si/latin/e/sb/latin/e/sbi/latin/e/ssr/latin/e/ssb/latin/e/ai/latin/e/mkt/latin/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"},{"id":10,"url":"https://glyph.medium.com/css/e/mkt/latin/elv8.css"},{"id":13,"url":"https://glyph.medium.com/css/e/sr/latin/e/si/latin/e/sb/latin/e/sbi/latin/e/ssr/latin/e/ssb/latin/e/mkt/latin/e/elv8r/latin/elv8.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"405c527e33877e2f\",\"ot-tracer-traceid\":\"797df52d06f470a0\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email","user_friends"],"connect":["public_profile","email","user_friends"],"login":["public_profile","email","user_friends"],"share":["public_profile","email","user_friends","publish_actions"]}},"mailingListArchiveUploadSizeMb":2,"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"goldfinchUrl":"https://goldfinch.medium.com","buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":2,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"lo_post_page_4","type":0,"url":"www.calendly.com"},{"promptId":"lo_home_page","type":1,"url":"www.calendly.com"},{"promptId":"lo_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","paypalClientMode":"production","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"KE","bypassMeter":false}
// ]]></script><script charset="UTF-8" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/main-base.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"bfeb6ae54ec0","versionId":"d4f6a086b2b9","creatorId":"5736bd18104c","creator":{"userId":"5736bd18104c","name":"Matt Hardwick","username":"mrhwick","createdAt":1374453992514,"lastPostCreatedAt":1517595698136,"imageId":"0*w9URdmuBdJxuElHz.jpeg","backgroundImageId":"","bio":"Software Engineer. Computer Scientist. Fascinated with the world at large and my place in it.","twitterScreenName":"MRHwick","socialStats":{"userId":"5736bd18104c","usersFollowedCount":43,"usersFollowedByCount":35,"type":"SocialStats"},"social":{"userId":"lo_j4q52oOnOkJ1","targetUserId":"5736bd18104c","type":"Social"},"facebookAccountId":"10208702028840523","allowNotes":1,"isNsfw":false,"type":"User"},"homeCollectionId":"","title":"Simple Lane Detection with OpenCV","detectedLanguage":"en","latestVersion":"d4f6a086b2b9","latestPublishedVersion":"d4f6a086b2b9","hasUnpublishedEdits":false,"latestRev":3386,"createdAt":1489932362354,"updatedAt":1525580451896,"acceptedAt":0,"firstPublishedAt":1490034102388,"latestPublishedAt":1514584890332,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Using OpenCV and Python to Detect Road Lanes","bodyModel":{"paragraphs":[{"name":"e478","type":3,"text":"Simple Lane Detection with OpenCV","markups":[]},{"name":"5196","type":11,"text":"The final product of my own pipeline for lane line detection and rendering on a video. We’ll be rebuilding a simpler version of this pipeline in this post.","markups":[],"layout":3,"iframe":{"mediaResourceId":"1261e5fbaff3798b46e4cf21ee5a8f53","iframeWidth":854,"iframeHeight":480,"thumbnailUrl":"https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMR5W03V-ldY%2Fhqdefault.jpg&key=4fce0568f2ce49e8b54624ef71a8a5bd"}},{"name":"8ab1","type":1,"text":"This post is the second in my series about the projects and challenges of Udacity’s nano-degree on self-driving vehicle engineering.","markups":[{"type":3,"start":27,"end":131,"href":"https://medium.com/@mrhwick/embarking-on-a-self-driving-journey-fe368795fe34#.7bnvcuv3v","title":"","rel":"","anchorType":0}],"hasDropCap":true},{"name":"62af","type":3,"text":"Introduction","markups":[]},{"name":"ef46","type":1,"text":"In this post, we’ll be doing a deep dive on the techniques that I’ve learned for a very simple lane detection algorithm. The problem we solve in this post is to take a simple video as input data and process it to detect the lane within which the vehicle is moving. Then we will find a representative line for both the left and right lane lines and render those representations back out to the video as a red overlay. This post will be heavy on technical details about how to use the libraries available in the Python computer vision ecosystem to solve this problem.","markups":[]},{"name":"8311","type":1,"text":"Computer vision is an area of computer science devoted to the extraction and processing of structured information from mostly-unstructured image data. We are going to use OpenCV to process the input images to discover any lane lines held within and also for rendering out a representation of the lane. Additionally, images are really just dense matrix data, so we will use numpy and matplotlib to do transformations and rendering of image data. I’ve run all of this code within a Jupyter notebook, but you can run it in any environment that allows you to install the dependencies and execute python scripts.","markups":[{"type":3,"start":171,"end":177,"href":"http://opencv.org/","title":"","rel":"","anchorType":0},{"type":3,"start":373,"end":378,"href":"http://www.numpy.org/","title":"","rel":"","anchorType":0},{"type":3,"start":383,"end":393,"href":"http://matplotlib.org/","title":"","rel":"","anchorType":0},{"type":3,"start":480,"end":487,"href":"http://jupyter.org/","title":"","rel":"","anchorType":0}]},{"name":"0651","type":1,"text":"By the end of this post, you will have learned how to write a program that can do the conversion below.","markups":[]},{"name":"134f","type":4,"text":"From raw image to rendered lane lines","markups":[],"layout":3,"metadata":{"id":"1*a2owzhUlg_3telqyYz7avA.png","originalWidth":2318,"originalHeight":662}},{"name":"e94f","type":3,"text":"Solving an Easier Problem","markups":[]},{"name":"e3f0","type":1,"text":"First of all, one obvious way to make the problem easier is to work out our solution for a single image. A video is, after all, just a series of images. We can then move on to running our pipeline on an input video frame-by-frame as a final solution to the original problem of processing an entire video for lane detection.","markups":[]},{"name":"b801","type":1,"text":"For example, let’s take the single image frame below.","markups":[]},{"name":"5cfd","type":4,"text":"A sample input image frame.","markups":[],"layout":3,"metadata":{"id":"1*BdZPGulJercHGEY6IREMVA.png","originalWidth":1159,"originalHeight":662}},{"name":"c5d0","type":1,"text":"In the above image, the lane markers are obvious to any human observer. We perform processing of this image intuitively, and after being trained to drive a human can detect the lane in which the vehicle appears to be moving. Humans also effortlessly identify many other objects in the scene, such as the other vehicles, the embankment near the right shoulder, some road signs alongside the road, and even the mountains visible on the horizon. While many of these objects are complex in visual structure, it could be said that the lane markers are actually some of the simplest structures in the image!","markups":[]},{"name":"b510","type":1,"text":"Pre-existing knowledge of driving gives us certain assumptions about the properties and structure of a lane, further simplifying the problem. One obvious assumption is that the lane is oriented to be parallel with the direction of movement. This being the case, the lines denoting the lane will tend to extend from the foreground of an image into the background along paths that are angled slightly inwards. We can also assume that the lines will never quite reach the horizon, either disappearing with distance or being obscured by some other image feature along the way.","markups":[]},{"name":"ea58","type":1,"text":"One very simple filter on the image could be to crop out all of the areas which we believe will never contain information about the lane markers. We’ll kick off our project by writing the code necessary to do a simple crop of the region of interest.","markups":[]},{"name":"effe","type":3,"text":"Cropping to a Region of Interest","markups":[]},{"name":"309a","type":13,"text":"Loading an Image into Memory","markups":[]},{"name":"4c5e","type":1,"text":"The very first thing we must do before we can process an image is… read an image! The following snippet can be used to load an image from a file into an array of image data which can be manipulated in python:","markups":[]},{"name":"241e","type":8,"text":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","markups":[]},{"name":"8b35","type":8,"text":"# reading in an image","markups":[]},{"name":"805b","type":8,"text":"image = mpimg.imread('solidWhiteCurve.jpg')","markups":[]},{"name":"09b8","type":8,"text":"# printing out some stats and plotting the image","markups":[]},{"name":"6321","type":8,"text":"print('This image is:', type(image), 'with dimensions:', image.shape)\nplt.imshow(image)\nplt.show()","markups":[]},{"name":"ed95","type":1,"text":"In this code, we import the necessary library modules, load an image into memory, print some stats about the image, and display it in a plot, as below:","markups":[]},{"name":"1103","type":8,"text":"$ python load_image.py\nThis image is: \x3cclass 'numpy.ndarray'\x3e with dimensions: (540, 960, 3)","markups":[]},{"name":"89e2","type":4,"text":"A simple test image which we can use for analysis.","markups":[],"layout":3,"metadata":{"id":"1*sg5ZL439z6b9KtYSOQXCYA.png","originalWidth":1178,"originalHeight":694}},{"name":"6167","type":1,"text":"Great! Now we have an image in memory which we can now manipulate however we like in our python script. The image has dimensions (540, 960, 3), representing the height, width, and three color channels of the image, respectively. This image will be the example we use for testing our algorithm throughout this post.","markups":[]},{"name":"4640","type":13,"text":"Defining the Region of Interest","markups":[]},{"name":"25c0","type":1,"text":"Next, we’ll define a set of points which describe the region of interest we want to crop out of the original.","markups":[]},{"name":"05e1","type":1,"text":"If you have worked with computer graphics before (or even if you paid close attention to the plotted image above!), you realize that the point (0, 0) (the origin) is actually in the upper left corner of the image. This is not exactly intuitive for most people, because general mathematics education tends to only show coordinate systems starting with the origin in the bottom left corner. That being said, this will not cause a lot of complications at this stage aside from the fact that the y coordinates of our region of interest will be specified by their distance from the top of the image rather than from the bottom.","markups":[{"type":10,"start":143,"end":149},{"type":10,"start":492,"end":493}]},{"name":"e699","type":1,"text":"We want a region of interest that fully contains the lane lines. One simple shape that will achieve this goal is a triangle that begins at the bottom left corner of the image, proceeds to the center of the image at the horizon, and then follows another edge to the bottom right corner of the image. Those vertices are defined as follows:","markups":[]},{"name":"db78","type":8,"text":"region_of_interest_vertices = [\n    (0, height),\n    (width / 2, height / 2),\n    (width, height),\n]","markups":[]},{"name":"6634","type":13,"text":"Cropping the Region of Interest","markups":[]},{"name":"de43","type":1,"text":"To actually do the cropping of the image, we’ll define a utility function region_of_interest():","markups":[{"type":10,"start":74,"end":94}]},{"name":"2a38","type":8,"text":"import numpy as np\nimport cv2","markups":[]},{"name":"d8cc","type":8,"text":"def region_of_interest(img, vertices):\n    # Define a blank matrix that matches the image height/width.\n    mask = np.zeros_like(img)","markups":[]},{"name":"0216","type":8,"text":"    # Retrieve the number of color channels of the image.\n    channel_count = img.shape[2]","markups":[]},{"name":"beec","type":8,"text":"    # Create a match color with the same color channel counts.\n    match_mask_color = (255,) * channel_count\n      \n    # Fill inside the polygon\n    cv2.fillPoly(mask, vertices, match_mask_color)\n    \n    # Returning the image only where mask pixels match\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image","markups":[]},{"name":"e60b","type":1,"text":"And then we’ll run the cropping function on our image before showing it again (output below):","markups":[]},{"name":"6376","type":8,"text":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","markups":[]},{"name":"378b","type":8,"text":"region_of_interest_vertices = [\n    (0, height),\n    (width / 2, height / 2),\n    (width, height),\n]","markups":[]},{"name":"dcfe","type":8,"text":"image = mpimg.imread('solidWhiteCurve.jpg')","markups":[]},{"name":"cb9e","type":8,"text":"cropped_image = region_of_interest(\n    image,\n    np.array([region_of_interest_vertices], np.int32),\n)","markups":[]},{"name":"96f8","type":8,"text":"plt.figure()\nplt.imshow(cropped_image)","markups":[]},{"name":"473a","type":8,"text":"plt.show()","markups":[]},{"name":"9ad7","type":4,"text":"Cropped image with most of the peripheral objects removed!","markups":[],"layout":3,"metadata":{"id":"1*1OmU-0kFcKljoYdiZk1lGQ.png","originalWidth":2578,"originalHeight":1092}},{"name":"db5b","type":3,"text":"Detecting Edges in the Cropped Image","markups":[]},{"name":"79e5","type":1,"text":"Now we have a cropped image to work with, in less than 2o lines of code! Even better, we have used a fairly simple shape and yet still managed to remove almost all of the objects from the image that are unrelated to the lane or lane markings.","markups":[]},{"name":"6c64","type":1,"text":"The next part of our pipeline will be detecting shape edges in the remaining (cropped) image data. We need a bit of mathematical theory to get an intuition about what is happening in this part, but I’m not going to get too technical on the concepts. Interested readers can follow the links provided to learn more.","markups":[]},{"name":"8e21","type":13,"text":"Mathematics of Edge Detection","markups":[]},{"name":"55aa","type":1,"text":"First, a question that will help us build an intuition about the process of edge detection:","markups":[]},{"name":"568e","type":6,"text":"In terms of the mathematical information in an image (a matrix of data), what actually defines an edge?","markups":[]},{"name":"3a3b","type":1,"text":"To answer that question, let’s look closely at a lane marking that we hope to detect.","markups":[]},{"name":"dbb8","type":4,"text":"A lane marking with a highlighted section illustrating the gradient of an edge.","markups":[],"layout":4,"metadata":{"id":"1*v9y-rItOhCwh-u1NyZs3Cw.png","originalWidth":1142,"originalHeight":708}},{"name":"2e31","type":1,"text":"If we pay close attention to the data surrounding this edge, it is fairly intuitive to conclude that edges are simply the areas of an image where the color values change very quickly. Therefore, detecting edges in an image becomes a mathematics problem of detecting any area where a pixel is a mismatch in color to all of its neighbors.","markups":[{"type":2,"start":122,"end":182}]},{"name":"3594","type":1,"text":"Fortunately for us, this mathematics problem is very solvable. In fact, computer scientist John F. Canny invented an algorithm to do just that, using calculus of variations to achieve his solution. For those of you that have studied calculus before, it will be sensible that Canny Edge Detection essentially detects areas of the image that have a strong gradient in the image’s color function. Canny also adds a pair of intensity threshold parameters which indicate generally how strong an edge must be to be detected. See this video for a good explanation.","markups":[{"type":3,"start":91,"end":104,"href":"https://en.wikipedia.org/wiki/John_Canny","title":"","rel":"","anchorType":0},{"type":3,"start":114,"end":142,"href":"https://en.wikipedia.org/wiki/Canny_edge_detector","title":"","rel":"","anchorType":0},{"type":3,"start":150,"end":172,"href":"https://en.wikipedia.org/wiki/Calculus_of_variations","title":"","rel":"","anchorType":0},{"type":3,"start":523,"end":556,"href":"https://www.youtube.com/watch?v=sRFM5IEqR2w","title":"","rel":"","anchorType":0}]},{"name":"8d67","type":13,"text":"Grayscale Conversion and Canny Edge Detection","markups":[]},{"name":"1b25","type":1,"text":"We don’t actually care about the colors of the picture at all, just the differences between their intensity values. In order to make the edge detection process simpler, we can convert the image into grayscale. This will remove color information and replace it with a single intensity value for each pixel of the image. Now our solution is to use Canny Edge Detection to find areas of the image that rapidly change over the intensity value.","markups":[]},{"name":"dd91","type":1,"text":"For those of us that aren’t interested writing this algorithm ourselves, OpenCV ships with a single call implementation ready to use. Let’s try running the Canny Edge Detection algorithm on our cropped image with some reasonable starter thresholds.","markups":[{"type":3,"start":73,"end":132,"href":"http://docs.opencv.org/trunk/da/d22/tutorial_py_canny.html","title":"","rel":"","anchorType":0}]},{"name":"ef5b","type":8,"text":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport cv2\nimport math","markups":[]},{"name":"7a33","type":8,"text":"def region_of_interest(img, vertices):\n    mask = np.zeros_like(img)\n    channel_count = img.shape[2]\n    match_mask_color = (255,) * channel_count\n    cv2.fillPoly(mask, vertices, match_mask_color)\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image","markups":[]},{"name":"26f6","type":8,"text":"region_of_interest_vertices = [\n    (0, height),\n    (width / 2, height / 2),\n    (width, height),\n]","markups":[]},{"name":"bf41","type":8,"text":"image = mpimg.imread('solidWhiteCurve.jpg')","markups":[]},{"name":"337d","type":8,"text":"cropped_image = region_of_interest(\n    image,\n    np.array([region_of_interest_vertices], np.int32),\n)\nplt.figure()\nplt.imshow(cropped_image)","markups":[]},{"name":"0bbf","type":8,"text":"# Convert to grayscale here.\ngray_image = cv2.cvtColor(cropped_image, cv2.COLOR_RGB2GRAY)","markups":[]},{"name":"c9e4","type":8,"text":"# Call Canny Edge Detection here.\ncannyed_image = cv2.Canny(gray_image, 100, 200)","markups":[]},{"name":"32b5","type":8,"text":"plt.figure()\nplt.imshow(cannyed_image)","markups":[]},{"name":"5b70","type":8,"text":"plt.show()","markups":[]},{"name":"116f","type":4,"text":"Our cropped image with edges shown as a series of many single pixels.","markups":[],"layout":3,"metadata":{"id":"1*oY2VO6ST1HejhdbqTlIP3A.png","originalWidth":2390,"originalHeight":666}},{"name":"896a","type":1,"text":"We did it!, the image now contains only the single pixels which are indicative of an edge. But there’s a problem… We accidentally detected the edges of our cropped region of interest!","markups":[]},{"name":"ffee","type":1,"text":"Not to worry, we can fix this problem by simply place the region of interest cropping after the Canny process in our pipeline. We also need to adjust the region of interest utility function to account for the fact that our image is now grayscale:","markups":[]},{"name":"4202","type":8,"text":"def region_of_interest(img, vertices):\n    mask = np.zeros_like(img)","markups":[]},{"name":"d24e","type":8,"text":"    match_mask_color = 255 # \x3c-- This line altered for grayscale.\n    \n    cv2.fillPoly(mask, vertices, match_mask_color)\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image","markups":[]},{"name":"836d","type":8,"text":"region_of_interest_vertices = [\n    (0, height),\n    (width / 2, height / 2),\n    (width, height),\n]","markups":[]},{"name":"7dd2","type":8,"text":"image = mpimg.imread('solidWhiteCurve.jpg')","markups":[]},{"name":"22f1","type":8,"text":"plt.figure()\nplt.imshow(image)","markups":[]},{"name":"5f5c","type":8,"text":"plt.show()","markups":[]},{"name":"b087","type":8,"text":"gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\ncannyed_image = cv2.Canny(gray_image, 100, 200)","markups":[]},{"name":"f767","type":8,"text":"# Moved the cropping operation to the end of the pipeline.\ncropped_image = region_of_interest(\n    cannyed_image,\n    np.array([region_of_interest_vertices], np.int32)\n)","markups":[]},{"name":"3bef","type":8,"text":"plt.figure()\nplt.imshow(cropped_image)","markups":[]},{"name":"8703","type":8,"text":"plt.show()","markups":[]},{"name":"6d52","type":1,"text":"Now let’s run our pipeline once more.","markups":[]},{"name":"90ed","type":4,"text":"Cropping after running Canny Edge Detection.","markups":[],"layout":3,"metadata":{"id":"1*_H6fK01cMRNanpuISluQ7w.png","originalWidth":2422,"originalHeight":654}},{"name":"ad0f","type":3,"text":"Generating Lines from Edge Pixels","markups":[]},{"name":"b3ad","type":1,"text":"Perfect! This looks like a pretty good start for detecting the lane markings. It appears, in our output image, that the most prominent features of our processed image are indeed the lane markings. Now that we have the image processed down to a set of pixels representing edges, we need to link these pixels together to generate a list of lines. This is another problem that can be solved using some rather complicated mathematics theory. Don’t worry; we’ll stay on the surface level, again, unless you want to follow the links.","markups":[]},{"name":"1e81","type":13,"text":"Mathematics of Line Detection","markups":[]},{"name":"e8cd","type":1,"text":"To get an intuition about the problem, let’s think about a similar question to the one that we posed about edge detection:","markups":[]},{"name":"433d","type":6,"text":"In terms of the mathematical information in an image (a matrix of data), what actually defines a line?","markups":[]},{"name":"6ea9","type":1,"text":"We have an image consisting of mostly blank pixels and a few scattered ‘edge pixels’ that have no known structure, but can easily be recognized as a line to a human observer. To answer our question, let’s take another look at the same lane marking from the edge detection example.","markups":[]},{"name":"302d","type":4,"text":"The same lane marking example, post edge detection. Line candidates marked in blue.","markups":[],"layout":4,"metadata":{"id":"1*7U04EK1WHgVBQkWkOkM2yA.png","originalWidth":1118,"originalHeight":666}},{"name":"e614","type":1,"text":"If we pay close attention to a region that appears to be a line, we find that the edge pixels have something in common. We can imagine all the possible lines that pass through each pixel, but the points share only a few lines in common. These common lines can be thought of as candidates for the actual line (if it exists) that passes through all of the nearby edge pixels.","markups":[]},{"name":"fa31","type":1,"text":"We have changed the difficult problem of interpreting many lines out of an entire image matrix of edge pixels and zeros into the much simpler problem of discovering lines which intersect multiple edge pixels at once. Although this is an easier problem, trial and error will not work. There are infinitely many lines that pass through each of the edge pixels, so we cannot simply test all of the lines to see if they match many of the pixels around a selected pixel. We can, however, use a mathematical trick to transform the input in such a way that there is a single solution for each line that we do want to discover.","markups":[]},{"name":"5a59","type":1,"text":"The main concept we will be using here is called a Hough Transform. Using a Hough Transform, we will transform all of our edge pixels into a different mathematical form. Once the transformation is complete, each edge pixel in “Image Space” will have become a line or curve in “Hough Space”. In Hough Space, each line represents a point from Image Space, and each point represents a line from Image Space. For a detailed explanation of this concept, check out this video.","markups":[{"type":3,"start":51,"end":66,"href":"https://en.wikipedia.org/wiki/Hough_transform","title":"","rel":"","anchorType":0},{"type":3,"start":459,"end":469,"href":"https://www.youtube.com/watch?v=4zHbI-fFIlI","title":"","rel":"","anchorType":0}]},{"name":"9b55","type":4,"text":"An illustration of an Image Space and it’s corresponding Hough Space (slope-intercept parameters). (Source)","markups":[{"type":3,"start":100,"end":106,"href":"https://alyssaq.github.io/2014/understanding-hough-transform/","title":"","rel":"","anchorType":0}],"layout":1,"metadata":{"id":"1*vPOSeUrdpDJ11q11TF_gpg.png","originalWidth":1922,"originalHeight":946}},{"name":"85db","type":1,"text":"We do not need to cover more detail about the mathematics involved in performing the Hough Transform. It is enough to know that this greatly simplifies the problem we need to solve.","markups":[]},{"name":"e89f","type":1,"text":"To the point, we now do not need to solve for a line that intersects all nearby edge pixels. Instead, we can simply solve for the intersections between lines in Hough Space, and transform that intersection point back into Image Space to obtain a line which intersects enough edge pixels. The inputs to the Hough Transform can be varied to alter which lines are considered a real feature of the scene and which are just clutter.","markups":[]},{"name":"1bf7","type":13,"text":"Using Hough Transforms to Detect Lines","markups":[]},{"name":"c245","type":1,"text":"Fortunately for us, OpenCV ships with a function for generating Hough lines from an image containing edge pixels. We will run this algorithm on our image with some reasonable parameters. This will generate a listing of all the lines believed by the Hough Transform to be a part of the scene and not a bit of clutter from the previous edge detection step.","markups":[{"type":3,"start":38,"end":75,"href":"http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html","title":"","rel":"","anchorType":0}]},{"name":"790f","type":8,"text":"...","markups":[]},{"name":"507d","type":8,"text":"image = mpimg.imread('solidWhiteCurve.jpg')","markups":[]},{"name":"82b7","type":8,"text":"gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\ncannyed_image = cv2.Canny(gray_image, 200, 300)\ncropped_image = region_of_interest(\n    cannyed_image,\n    np.array(\n        [region_of_interest_vertices],\n        np.int32\n    ),\n)","markups":[]},{"name":"2ca2","type":8,"text":"lines = cv2.HoughLinesP(\n    cropped_image,\n    rho=6,\n    theta=np.pi / 60,\n    threshold=160,\n    lines=np.array([]),\n    minLineLength=40,\n    maxLineGap=25\n)\nprint(lines)","markups":[]},{"name":"f3e8","type":1,"text":"The printout of the detected lines will be similar to below:","markups":[]},{"name":"2a0d","type":8,"text":"$ python load_image.py\n\n[[[486 312 877 538]]","markups":[]},{"name":"d33b","type":8,"text":"[[724 441 831 502]]","markups":[]},{"name":"5978","type":8,"text":"...","markups":[]},{"name":"bbe1","type":8,"text":"[[386 382 487 309]]]","markups":[]},{"name":"c0cf","type":1,"text":"Each line is represented by four numbers, which are the two endpoints of the detected line segment, like so","markups":[]},{"name":"2b49","type":8,"text":"[x1, y1, x2, y2]","markups":[]},{"name":"8e94","type":1,"text":"If we tweak the rho, theta, threshold, minLineLength, and maxLineGap parameters, we can detect many different kinds of lines within the image data. I encourage you to play with the values of these parameters at the end of this section of the article to see the effects that they have on line detection for yourself.","markups":[{"type":10,"start":16,"end":19},{"type":10,"start":21,"end":26},{"type":10,"start":28,"end":37},{"type":10,"start":39,"end":52},{"type":10,"start":58,"end":68}]},{"name":"a2bd","type":13,"text":"Rendering Detected Hough Lines as an Overlay","markups":[]},{"name":"770e","type":1,"text":"The last thing we will do with line detection is render the detected lines back onto the image itself, to give us a sense of the real features in the scene which are being detected. For this rendering, we’ll need to write another utility function:","markups":[]},{"name":"e1a2","type":8,"text":"def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n    # If there are no lines to draw, exit.\n        if lines is None:\n            return","markups":[]},{"name":"139b","type":8,"text":"    # Make a copy of the original image.\n    img = np.copy(img)","markups":[]},{"name":"2127","type":8,"text":"    # Create a blank image that matches the original in size.\n    line_img = np.zeros(\n        (\n            img.shape[0],\n            img.shape[1],\n            3\n        ),\n        dtype=np.uint8,\n    )","markups":[]},{"name":"86a4","type":8,"text":"    # Loop over all lines and draw them on the blank image.\n    for line in lines:\n        for x1, y1, x2, y2 in line:\n            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)","markups":[]},{"name":"2e34","type":8,"text":"    # Merge the image with the lines onto the original.\n    img = cv2.addWeighted(img, 0.8, line_image, 1.0, 0.0)","markups":[]},{"name":"6512","type":8,"text":"    # Return the modified image.\n    return img","markups":[]},{"name":"20aa","type":1,"text":"And then we’ll use this utility function inside of our processing script.","markups":[]},{"name":"9c75","type":8,"text":"...","markups":[]},{"name":"347b","type":8,"text":"image = mpimg.imread('solidWhiteCurve.jpg')","markups":[]},{"name":"10b2","type":8,"text":"plt.figure()\nplt.imshow(image)","markups":[]},{"name":"630b","type":8,"text":"plt.show()","markups":[]},{"name":"e818","type":8,"text":"gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\ncannyed_image = cv2.Canny(gray_image, 100, 200)\ncropped_image = region_of_interest(\n    cannyed_image,\n    np.array(\n        [region_of_interest_vertices],\n        np.int32\n    ),\n)\nlines = cv2.HoughLinesP(\n    cropped_image,\n    rho=6,\n    theta=np.pi / 60,\n    threshold=160,\n    lines=np.array([]),\n    minLineLength=40,\n    maxLineGap=25\n)","markups":[]},{"name":"1db8","type":8,"text":"line_image = draw_lines(image, lines) # \x3c---- Add this call.","markups":[]},{"name":"1abe","type":8,"text":"plt.figure()\nplt.imshow(line_image)","markups":[]},{"name":"9107","type":8,"text":"plt.show()","markups":[]},{"name":"0446","type":4,"text":"Output of our pipeline once we have rendered the detected lines back onto the original image.","markups":[],"layout":3,"metadata":{"id":"1*RKs77nfqXQQ30WnvkAsHHw.png","originalWidth":2390,"originalHeight":668}},{"name":"2f1c","type":1,"text":"Awesome! Now we have a copy of the original with the detected lines rendered as an overlay. This is very cool, but we want to distinguish the left and right lane lines independently and show a single line for each. In the next section, we’ll create a single line for each group of detected lane markings.","markups":[]},{"name":"57ad","type":3,"text":"Creating a Single Left and Right Lane Line","markups":[]},{"name":"6345","type":1,"text":"The final step in our pipeline will be to create only one line for each of the groups of lines we found in the last step. This can be done by fitting a simple linear model to the various endpoints of the line segments in each group, then rendering a single overlay line on that linear model.","markups":[]},{"name":"df59","type":13,"text":"Grouping the Lines into Left and Right Groups","markups":[]},{"name":"0d24","type":1,"text":"First, though, we need to determine which lines are in the left group, and which are in the right group.","markups":[]},{"name":"2d1d","type":1,"text":"For those who have taken algebra, one obvious difference between the two groups of line segments is the direction of their slope. The slope of a line measures the angle of that line, with a horizontal line having a slope of 0 and a vertical line having a slope of ∞. Almost all of the lines we will detect will have a slope somewhere in between these two values, because they are angled from the bottom of the image towards the center at the horizon.","markups":[{"type":10,"start":224,"end":225}]},{"name":"824b","type":1,"text":"Most importantly, the direction of a line’s slope describes whether the line is moving up or down as you travel along the line from left to right. A line with negative slope is said to be traveling downwards, while a line with positive slope is said to be traveling upwards. This is how slope direction works in normal coordinate systems where the origin is at the bottom left corner. In our coordinate system, however, the origin is in the top left corner, and so our slope directions will be reversed, with negative slopes traveling upwards and positive slopes traveling downwards.","markups":[]},{"name":"17b9","type":1,"text":"In our images, the left lane markings all have a negative slope, meaning the lines travel upwards towards the horizon as we move from left to right along the lines. On the other hand, all of our right lane markings have a positive slope, traveling downwards towards the bottom of the image as we move along them from left to right. This will be the distinction we use to group the left and right lines. Furthermore, the lane markings appear extreme in slope, so we will not consider any line with a slope absolute value less than 0.5. This means that we’ll reject any line which doesn’t move quickly towards the horizon or the bottom of the image, leaving only lines which are nearer to vertical than horizontal.","markups":[{"type":10,"start":530,"end":533}]},{"name":"cb75","type":8,"text":"...","markups":[]},{"name":"e44b","type":8,"text":"left_line_x = []\nleft_line_y = []\nright_line_x = []\nright_line_y = []","markups":[]},{"name":"c4ac","type":8,"text":"for line in lines:\n    for x1, y1, x2, y2 in line:\n        slope = (y2 - y1) / (x2 - x1) # \x3c-- Calculating the slope.\n        if math.fabs(slope) \x3c 0.5: # \x3c-- Only consider extreme slope\n            continue\n        if slope \x3c= 0: # \x3c-- If the slope is negative, left group.\n            left_line_x.extend([x1, x2])\n            left_line_y.extend([y1, y2])\n        else: # \x3c-- Otherwise, right group.\n            right_line_x.extend([x1, x2])\n            right_line_y.extend([y1, y2])","markups":[]},{"name":"4fcf","type":1,"text":"In this snippet, we loop over all of the lines we’ve detected and calculate their slope. If the slope is not extreme enough to be a lane marking edge, we will not consider it at all, and continue the loop without handling that line. If the slope is negative, the line belongs to the left lane markings group. If the slope is positive, the line belongs to the right group. To add a line to either group, we add the various x and y endpoint coordinates to lists for each side.","markups":[{"type":10,"start":422,"end":423},{"type":10,"start":428,"end":429}]},{"name":"6224","type":13,"text":"Creating a Single Linear Representation of each Line Group","markups":[]},{"name":"3971","type":1,"text":"The second challenge in our single line creation problem is to average the lines in each group into a single line that fits pretty closely in orientation and location in the image.","markups":[]},{"name":"2fff","type":1,"text":"Think about known values that we can work from to generate the left and right lane lines. Two known values are the y values for the top and bottom endpoints of the segments, which both lane lines will hold in common. We want the lines to begin at the bottom of the image, and travel along the lane markings towards the horizon, ending just below the horizon. The problem then becomes an exercise of finding the correct x values for each point of the two line segments.","markups":[{"type":10,"start":115,"end":116},{"type":10,"start":419,"end":420}]},{"name":"b295","type":8,"text":"min_y = image.shape[0] * (3 / 5) # \x3c-- Just below the horizon\nmax_y = image.shape[0] # \x3c-- The bottom of the image","markups":[]},{"name":"4712","type":1,"text":"In order to find the correct x values for the top and bottom points of each line, we can develop two functions f(y) = x that define the left and right lines. Then we can feed the two common y values into the functions to find the x values that complete our endpoint coordinates. This function needs to be a linear fit to the coordinates in each group in order to average our detected lines, and fortunately numpy provides some functions to do it!","markups":[{"type":10,"start":29,"end":30},{"type":10,"start":111,"end":119},{"type":10,"start":190,"end":191},{"type":10,"start":230,"end":231}]},{"name":"586c","type":1,"text":"The polyfit and poly1d operations can generate a linear function that match the two given spaces (x and y) for each group.","markups":[{"type":10,"start":98,"end":99},{"type":10,"start":104,"end":105},{"type":3,"start":4,"end":11,"href":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html","title":"","rel":"","anchorType":0},{"type":3,"start":16,"end":22,"href":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.poly1d.html","title":"","rel":"","anchorType":0}]},{"name":"cb73","type":8,"text":"...","markups":[]},{"name":"aeee","type":8,"text":"poly_left = np.poly1d(np.polyfit(\n    left_line_y,\n    left_line_x,\n    deg=1\n))","markups":[]},{"name":"63a1","type":8,"text":"left_x_start = int(poly_left(max_y))\nleft_x_end = int(poly_left(min_y))","markups":[]},{"name":"d11e","type":8,"text":"poly_right = np.poly1d(np.polyfit(\n    right_line_y,\n    right_line_x,\n    deg=1\n))","markups":[]},{"name":"8f10","type":8,"text":"right_x_start = int(poly_right(max_y))\nright_x_end = int(poly_right(min_y))","markups":[]},{"name":"804f","type":1,"text":"Now we can use these lines as our input to the draw_lines function in our pipeline:","markups":[{"type":10,"start":47,"end":57}]},{"name":"163b","type":8,"text":"...","markups":[]},{"name":"8265","type":8,"text":"image = mpimg.imread('solidWhiteCurve.jpg')","markups":[]},{"name":"9bac","type":8,"text":"plt.figure()\nplt.imshow(image)","markups":[]},{"name":"da52","type":8,"text":"gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\ncannyed_image = cv2.Canny(gray_image, 100, 200)\ncropped_image = region_of_interest(\n    cannyed_image,\n    np.array(\n        [region_of_interest_vertices],\n        np.int32\n    ),\n)\nlines = cv2.HoughLinesP(\n    cropped_image,\n    rho=6,\n    theta=np.pi / 60,\n    threshold=160,\n    lines=np.array([]),\n    minLineLength=40,\n    maxLineGap=25\n)","markups":[]},{"name":"1271","type":8,"text":"left_line_x = []\nleft_line_y = []\nright_line_x = []\nright_line_y = []","markups":[]},{"name":"0919","type":8,"text":"for line in lines:\n    for x1, y1, x2, y2 in line:\n        slope = (y2 - y1) / (x2 - x1) # \x3c-- Calculating the slope.\n        if math.fabs(slope) \x3c 0.5: # \x3c-- Only consider extreme slope\n            continue\n        if slope \x3c= 0: # \x3c-- If the slope is negative, left group.\n            left_line_x.extend([x1, x2])\n            left_line_y.extend([y1, y2])\n        else: # \x3c-- Otherwise, right group.\n            right_line_x.extend([x1, x2])\n            right_line_y.extend([y1, y2])","markups":[]},{"name":"d7f9","type":8,"text":"min_y = image.shape[0] * (3 / 5) # \x3c-- Just below the horizon\nmax_y = image.shape[0] # \x3c-- The bottom of the image","markups":[]},{"name":"73d3","type":8,"text":"poly_left = np.poly1d(np.polyfit(\n    left_line_y,\n    left_line_x,\n    deg=1\n))","markups":[]},{"name":"fb1d","type":8,"text":"left_x_start = int(poly_left(max_y))\nleft_x_end = int(poly_left(min_y))","markups":[]},{"name":"d274","type":8,"text":"poly_right = np.poly1d(np.polyfit(\n    right_line_y,\n    right_line_x,\n    deg=1\n))","markups":[]},{"name":"e97e","type":8,"text":"right_x_start = int(poly_right(max_y))\nright_x_end = int(poly_right(min_y))","markups":[]},{"name":"659e","type":8,"text":"line_image = draw_lines(\n    image,\n    [[\n        [left_x_start, max_y, left_x_end, min_y],\n        [right_x_start, max_y, right_x_end, min_y],\n    ]],\n    thickness=5,\n)","markups":[]},{"name":"fdf1","type":8,"text":"plt.figure()\nplt.imshow(line_image)","markups":[]},{"name":"caaf","type":8,"text":"plt.show()","markups":[]},{"name":"7426","type":4,"text":"The final overlay of our two single lane lines.","markups":[],"layout":3,"metadata":{"id":"1*5HEIDnC0kxSW1F9r88S46A.png","originalWidth":2368,"originalHeight":622}},{"name":"4a8c","type":1,"text":"We did it!","markups":[]},{"name":"7332","type":3,"text":"Level Up: Annotate a Video","markups":[]},{"name":"a749","type":1,"text":"Now that we have an image processing pipeline to work with, we can actually apply the same techniques to a video to overlay our lane lines upon the video! We’ll use a test video which contains the image we have been working with above.","markups":[{"type":3,"start":165,"end":234,"href":"https://github.com/udacity/CarND-LaneLines-P1/blob/master/test_videos/solidWhiteRight.mp4","title":"","rel":"","anchorType":0}]},{"name":"5600","type":1,"text":"First, let’s put all of our current work into a defined function named pipeline().","markups":[{"type":10,"start":71,"end":81}]},{"name":"e4d6","type":8,"text":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport cv2\nimport math","markups":[]},{"name":"003e","type":8,"text":"def region_of_interest(img, vertices):\n    mask = np.zeros_like(img)\n    match_mask_color = 255\n    cv2.fillPoly(mask, vertices, match_mask_color)\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image","markups":[]},{"name":"cb3f","type":8,"text":"def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n    line_img = np.zeros(\n        (\n            img.shape[0],\n            img.shape[1],\n            3\n        ),\n        dtype=np.uint8\n    )\n    img = np.copy(img)\n    if lines is None:\n        return","markups":[]},{"name":"c67b","type":8,"text":"    for line in lines:\n        for x1, y1, x2, y2 in line:\n            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)","markups":[]},{"name":"81e1","type":8,"text":"    img = cv2.addWeighted(img, 0.8, line_img, 1.0, 0.0)","markups":[]},{"name":"c00d","type":8,"text":"    return img","markups":[]},{"name":"093f","type":8,"text":"def pipeline(image):\n    \"\"\"\n    An image processing pipeline which will output\n    an image with the lane lines annotated.\n    \"\"\"","markups":[]},{"name":"c78d","type":8,"text":"    height = image.shape[0]\n    width = image.shape[1]\n    region_of_interest_vertices = [\n        (0, height),\n        (width / 2, height / 2),\n        (width, height),\n    ]","markups":[]},{"name":"bb5e","type":8,"text":"    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)","markups":[]},{"name":"7b50","type":8,"text":"    cannyed_image = cv2.Canny(gray_image, 100, 200)\n \n    cropped_image = region_of_interest(\n        cannyed_image,\n        np.array(\n            [region_of_interest_vertices],\n            np.int32\n        ),\n    )\n \n    lines = cv2.HoughLinesP(\n        cropped_image,\n        rho=6,\n        theta=np.pi / 60,\n        threshold=160,\n        lines=np.array([]),\n        minLineLength=40,\n        maxLineGap=25\n    )\n \n    left_line_x = []\n    left_line_y = []\n    right_line_x = []\n    right_line_y = []\n \n    for line in lines:\n        for x1, y1, x2, y2 in line:\n            slope = (y2 - y1) / (x2 - x1)\n    if math.fabs(slope) \x3c 0.5:\n        continue\n    if slope \x3c= 0:\n        left_line_x.extend([x1, x2])\n        left_line_y.extend([y1, y2])\n    else:\n        right_line_x.extend([x1, x2])\n        right_line_y.extend([y1, y2])","markups":[]},{"name":"6d2c","type":8,"text":"    min_y = int(image.shape[0] * (3 / 5))\n    max_y = int(image.shape[0])","markups":[]},{"name":"852f","type":8,"text":"    poly_left = np.poly1d(np.polyfit(\n        left_line_y,\n        left_line_x,\n        deg=1\n    ))\n \n    left_x_start = int(poly_left(max_y))\n    left_x_end = int(poly_left(min_y))\n \n    poly_right = np.poly1d(np.polyfit(\n        right_line_y,\n        right_line_x,\n       deg=1\n    ))\n \n    right_x_start = int(poly_right(max_y))\n    right_x_end = int(poly_right(min_y))","markups":[]},{"name":"088b","type":8,"text":"    line_image = draw_lines(\n        image,\n        [[\n            [left_x_start, max_y, left_x_end, min_y],\n            [right_x_start, max_y, right_x_end, min_y],\n        ]],\n        thickness=5,\n    )","markups":[]},{"name":"5473","type":8,"text":"    return line_image","markups":[]},{"name":"de7f","type":1,"text":"And then we can write a video processing pipeline:","markups":[]},{"name":"4128","type":8,"text":"from moviepy.editor import VideoFileClip\nfrom IPython.display import HTML","markups":[]},{"name":"96ea","type":8,"text":"white_output = 'solidWhiteRight_output.mp4'\nclip1 = VideoFileClip(\"solidWhiteRight_input.mp4\")\nwhite_clip = clip1.fl_image(pipeline)\nwhite_clip.write_videofile(white_output, audio=False)","markups":[]},{"name":"4fed","type":1,"text":"After the video is finished processing, you should be able to open your video and have it match very nearly to the one below. Congratulations!","markups":[]},{"name":"3a22","type":11,"text":"","markups":[],"layout":3,"iframe":{"mediaResourceId":"1261e5fbaff3798b46e4cf21ee5a8f53","iframeWidth":854,"iframeHeight":480,"thumbnailUrl":"https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMR5W03V-ldY%2Fhqdefault.jpg&key=4fce0568f2ce49e8b54624ef71a8a5bd"}},{"name":"10fd","type":1,"text":"If you are interested in tinkering with this project further, you can visit the Udacity project repository here.","markups":[{"type":3,"start":80,"end":111,"href":"https://github.com/udacity/CarND-LaneLines-P1","title":"","rel":"","anchorType":0}]},{"name":"078a","type":1,"text":"I’ll leave you with some additional videos that I tested my pipeline on.","markups":[]},{"name":"f83a","type":11,"text":"","markups":[],"layout":3,"iframe":{"mediaResourceId":"8916de5c7d88fba75453c7e060d4ae2c","iframeWidth":854,"iframeHeight":480,"thumbnailUrl":"https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FJF4f31qK_og%2Fhqdefault.jpg&key=4fce0568f2ce49e8b54624ef71a8a5bd"}},{"name":"9bcc","type":11,"text":"","markups":[],"layout":3,"iframe":{"mediaResourceId":"ee953b2ba3e4357606c49e2bcca335d9","iframeWidth":854,"iframeHeight":480,"thumbnailUrl":"https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FyvyarXjTu9A%2Fhqdefault.jpg&key=4fce0568f2ce49e8b54624ef71a8a5bd"}}],"sections":[{"name":"df16","startIndex":0},{"name":"6dd0","startIndex":8}]},"postDisplay":{"coverless":true}},"virtuals":{"allowNotes":true,"previewImage":{"imageId":"1*a2owzhUlg_3telqyYz7avA.png","filter":"","backgroundSize":"","originalWidth":2318,"originalHeight":662,"strategy":"resample","height":0,"width":0},"wordCount":4304,"imageCount":11,"readingTime":17.541509433962265,"subtitle":"Using OpenCV and Python to Detect Road Lanes","usersBySocialRecommends":[],"recommends":28,"socialRecommends":[],"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":35160,"virtuals":{"isFollowing":false},"metadata":{"followerCount":23740,"postCount":35160,"coverImage":{"id":"1*KS2f1vPpoKL-tpqKl6uwbg.png","originalWidth":1212,"originalHeight":802,"isFeatured":true}},"type":"Tag"},{"slug":"udacity","name":"Udacity","postCount":2478,"virtuals":{"isFollowing":false},"metadata":{"followerCount":573,"postCount":2478,"coverImage":{"id":"1*yck6n31oeYSB8uFMnGwi-w.png","originalWidth":1204,"originalHeight":1514}},"type":"Tag"},{"slug":"self-driving-cars","name":"Self Driving Cars","postCount":11071,"virtuals":{"isFollowing":false},"metadata":{"followerCount":412632,"postCount":11071,"coverImage":{"id":"1*tui98o8Oqyt74hjjF4A_tA.jpeg"}},"type":"Tag"},{"slug":"autonomous-cars","name":"Autonomous Cars","postCount":4044,"virtuals":{"isFollowing":false},"metadata":{"followerCount":902,"postCount":4044,"coverImage":{"id":"1*2k2KLK8Yqhis7dVca43ESA@2x.jpeg","originalWidth":1163,"originalHeight":654,"backgroundSize":"","filter":"","isFeatured":false,"externalSrc":"","focusPercentX":-1,"focusPercentY":-1,"alt":"","repairedAt":0}},"type":"Tag"},{"slug":"opencv","name":"Opencv","postCount":403,"virtuals":{"isFollowing":false},"metadata":{"followerCount":145,"postCount":403,"coverImage":{"id":"1*J4rMK9ffat-gFKBwyN4_8Q.gif","originalWidth":360,"originalHeight":218,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":3,"links":{"entries":[{"url":"http://jupyter.org/","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/John_Canny","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Canny_edge_detector","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Hough_transform","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Calculus_of_variations","alts":[],"httpStatus":200},{"url":"https://alyssaq.github.io/2014/understanding-hough-transform/","alts":[],"httpStatus":200},{"url":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html","alts":[],"httpStatus":200},{"url":"https://docs.scipy.org/doc/numpy/reference/generated/numpy.poly1d.html","alts":[],"httpStatus":200},{"url":"http://matplotlib.org/","alts":[],"httpStatus":200},{"url":"http://www.numpy.org/","alts":[],"httpStatus":200},{"url":"https://github.com/udacity/CarND-LaneLines-P1/blob/master/test_videos/solidWhiteRight.mp4","alts":[],"httpStatus":200},{"url":"http://docs.opencv.org/trunk/da/d22/tutorial_py_canny.html","alts":[],"httpStatus":200},{"url":"http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html","alts":[],"httpStatus":200},{"url":"https://github.com/udacity/CarND-LaneLines-P1","alts":[],"httpStatus":200},{"url":"https://www.youtube.com/watch?v=4zHbI-fFIlI","alts":[{"type":2,"url":"vnd.youtube://www.youtube.com/watch?v=4zHbI-fFIlI&feature=applinks"},{"type":3,"url":"vnd.youtube://www.youtube.com/watch?v=4zHbI-fFIlI&feature=applinks"}],"httpStatus":200},{"url":"https://www.youtube.com/watch?v=sRFM5IEqR2w","alts":[{"type":2,"url":"vnd.youtube://www.youtube.com/watch?v=sRFM5IEqR2w&feature=applinks"},{"type":3,"url":"vnd.youtube://www.youtube.com/watch?v=sRFM5IEqR2w&feature=applinks"}],"httpStatus":200},{"url":"http://opencv.org/","alts":[],"httpStatus":200},{"url":"https://medium.com/@mrhwick/embarking-on-a-self-driving-journey-fe368795fe34#.7bnvcuv3v","alts":[{"type":2,"url":"medium://p/fe368795fe34"},{"type":3,"url":"medium://p/fe368795fe34"}],"httpStatus":200}],"version":"0.3","generatedAt":1514584896867},"isLockedPreviewOnly":false,"takeoverId":"","metaDescription":"","totalClapCount":159,"sectionCount":2,"readingList":0},"coverless":true,"slug":"simple-lane-detection-with-opencv","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"simple-lane-detection-with-opencv-bfeb6ae54ec0","previewContent":{"bodyModel":{"paragraphs":[{"name":"e478","type":3,"text":"Simple Lane Detection with OpenCV","markups":[],"alignment":1},{"name":"5196","type":11,"text":"","markups":[],"layout":9,"iframe":{"mediaResourceId":"1261e5fbaff3798b46e4cf21ee5a8f53","iframeWidth":854,"iframeHeight":480,"thumbnailUrl":"https://i.embed.ly/1/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMR5W03V-ldY%2Fhqdefault.jpg&key=4fce0568f2ce49e8b54624ef71a8a5bd"}}],"sections":[{"startIndex":0}]},"isFullContent":false},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0","approvedHomeCollectionId":"","newsletterId":"","webCanonicalUrl":"https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0","mediumUrl":"https://medium.com/@mrhwick/simple-lane-detection-with-opencv-bfeb6ae54ec0","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"isSponsored":false,"isRequestToPubDisabled":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"featureLockRequestMinimumGuaranteeAmount":0,"isElevate":false,"mongerRequestType":1,"type":"Post"},"mentionedUsers":[],"collaborators":[],"membershipPlans":[],"collectionUserRelations":[],"mode":null,"references":{"User":{"5736bd18104c":{"userId":"5736bd18104c","name":"Matt Hardwick","username":"mrhwick","createdAt":1374453992514,"lastPostCreatedAt":1517595698136,"imageId":"0*w9URdmuBdJxuElHz.jpeg","backgroundImageId":"","bio":"Software Engineer. Computer Scientist. Fascinated with the world at large and my place in it.","twitterScreenName":"MRHwick","socialStats":{"userId":"5736bd18104c","usersFollowedCount":43,"usersFollowedByCount":35,"type":"SocialStats"},"social":{"userId":"lo_j4q52oOnOkJ1","targetUserId":"5736bd18104c","type":"Social"},"facebookAccountId":"10208702028840523","allowNotes":1,"isNsfw":false,"type":"User"}},"Social":{"5736bd18104c":{"userId":"lo_j4q52oOnOkJ1","targetUserId":"5736bd18104c","type":"Social"}},"SocialStats":{"5736bd18104c":{"userId":"5736bd18104c","usersFollowedCount":43,"usersFollowedByCount":35,"type":"SocialStats"}}}})
// ]]></script><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/main-common-async.js"></script><script charset="UTF-8" src="Simple%20Lane%20Detection%20with%20OpenCV%20%E2%80%93%20Matt%20Hardwick%20%E2%80%93%20Medium_files/main-notes.js"></script></body></html>